
@article{haferAssessingOpenSource2009,
  title = {Assessing {{Open Source Software As}} a {{Scholarly Contribution}}},
  volume = {52},
  issn = {0001-0782},
  abstract = {Introduction Academic computer science has an odd relationship with software: Publishing papers about software is considered a distinctly stronger contribution than publishing the software. The historical reasons for this paradox no longer apply, but their legacy remains. This limits researchers who see the open-source software movement as an opportunity to make a scholarly contribution. Expanded definitions of scholarship acknowledge both application and discovery as important components.1 One obstacle remains: evaluation. To raise software to the status of a first-class contribution, we propose "best practices" for the evaluation of the scholarly contribution of open-source software. Typically, scholars who develop software do not include it as a primary contribution for performance reviews. Instead, they write articles about the software and present the articles as contributions. This conflation of articles and software serves neither medium well. An article describes an original intellectual contribution consisting of an idea, the argument for its importance and correctness, and supporting data. In contrast, software is more often an implementation of prior ideas in a usable form. It bridges the often considerable gap between an idea and the practical application of that idea. The original idea and its implementation represent distinct kinds of contribution. The critical gap is the perceived incomparability of these two contributions. Lacking a concise description adapted to the traditional practices of performance review committees, software is difficult to evaluate as a scholarly contribution and is often relegated to second-class status. We propose a framework for common assessment based on widely accepted definitions of scholarship. Within this general framework, we consider the material and procedures that a performance review committee uses to evaluate a publication. We then describe how software can be summarized in a compatible form of bibliographic citation and supplementary material.},
  number = {12},
  urldate = {2018-05-16},
  journal = {Commun. ACM},
  url = {http://doi.acm.org/10.1145/1610252.1610285},
  author = {Hafer, Lou and Kirkpatrick, Arthur E.},
  month = dec,
  year = {2009},
  pages = {126--129},
  file = {/home/stephan/Zotero/storage/46S98G52/Hafer und Kirkpatrick - 2009 - Assessing Open Source Software As a Scholarly Cont.pdf}
}

@article{howisonSoftwareScientificLiterature2016,
  title = {Software in the Scientific Literature: {{Problems}} with Seeing, Finding, and Using Software Mentioned in the Biology Literature},
  volume = {67},
  issn = {2330-1643},
  abstract = {Software is increasingly crucial to scholarship, yet the visibility and usefulness of software in the scientific record are in question. Just as with data, the visibility of software in publications is related to incentives to share software in reusable ways, and so promote efficient science. In this article, we examine software in publications through content analysis of a random sample of 90 biology articles. We develop a coding scheme to identify software ``mentions'' and classify them according to their characteristics and ability to realize the functions of citations. Overall, we find diverse and problematic practices: Only between 31\% and 43\% of mentions involve formal citations; informal mentions are very common, even in high impact factor journals and across different kinds of software. Software is frequently inaccessible (15\%\textendash{}29\% of packages in any form; between 90\% and 98\% of specific versions; only between 24\%\textendash{}40\% provide source code). Cites to publications are particularly poor at providing version information, whereas informal mentions are particularly poor at providing crediting information. We provide recommendations to improve the practice of software citation, highlighting recent nascent efforts. Software plays an increasingly great role in scientific practice; it deserves a clear and useful place in scholarly communication.},
  number = {9},
  journal = {Journal of the Association for Information Science and Technology},
  url = {http://dx.doi.org/10.1002/asi.23538},
  author = {Howison, James and Bullard, Julia},
  year = {2016},
  keywords = {bibliographic citations,biology,journals},
  pages = {2137--2155}
}

@book{jonesCodeMetaExchangeSchema2017,
  title = {{{CodeMeta}}: An Exchange Schema for Software Metadata. {{Version}} 2.0},
  url = {https://doi.org/10.5063/schema/codemeta-2.0},
  author = {Jones, Matthew B. and Boettiger, Carl and Mayes, Abby Cabunoc and Smith, Arfon and Slaughter, Peter and Niemeyer, Kyle and Gil, Yolanda and Fenner, Martin and Nowak, Krzysztof and Hahnel, Mark and Coy, Luke and Allen, Alice and Crosas, Merc{\`e} and Sands, Ashley and Hong, Neil Chue and Cruse, Patricia and Katz, Dan and Goble, Carole},
  year = {2017},
  doi = {10.5063/schema/codemeta-2.0},
  note = {Published: KNB Data Repository}
}

@article{neylonArticleLevelMetricsEvolution2009,
  title = {Article-{{Level Metrics}} and the {{Evolution}} of {{Scientific Impact}}},
  volume = {7},
  issn = {1545-7885},
  abstract = {The authors discuss the value of article-level metrics in determining an article's scientific impact.},
  language = {en},
  number = {11},
  urldate = {2019-08-14},
  journal = {PLOS Biology},
  url = {https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.1000242},
  author = {Neylon, Cameron and Wu, Shirley},
  month = nov,
  year = {2009},
  keywords = {Article-level metrics,Bibliometrics,Careers,Citation analysis,Peer review,Publication ethics,Scientific publishing,Scientists},
  pages = {e1000242},
  file = {/home/stephan/Zotero/storage/53Z4P2VQ/Neylon and Wu - 2009 - Article-Level Metrics and the Evolution of Scienti.pdf;/home/stephan/Zotero/storage/PFY8FBI2/article.html}
}

@article{zyczkowskiCitationGraphWeighted2010,
  title = {Citation Graph, Weighted Impact Factors and Performance Indices},
  volume = {85},
  issn = {1588-2861},
  abstract = {A scheme of evaluating an impact of a given scientific paper based on importance of papers quoting it is investigated. Introducing a weight of a given citation, dependent on the previous scientific achievements of the author of the citing paper, we define the weighting factor of a given scientist. Technically the weighting factors are defined by the components of the normalized leading eigenvector of the matrix describing the citation graph. The weighting factor of a given scientist, reflecting the scientific output of other researchers quoting his work, allows us to define weighted number of citation of a given paper, weighted impact factor of a journal and weighted Hirsch index of an individual scientist or of an entire scientific institution.},
  language = {en},
  number = {1},
  urldate = {2019-08-12},
  journal = {Scientometrics},
  url = {https://doi.org/10.1007/s11192-010-0208-6},
  author = {{\.Z}yczkowski, Karol},
  month = oct,
  year = {2010},
  keywords = {Citation graph,Citations,Performance index,Weighted bibliometric indices},
  pages = {301-315},
  file = {/home/stephan/Zotero/storage/IQ39X7JD/Życzkowski - 2010 - Citation graph, weighted impact factors and perfor.pdf}
}

@article{lawrenceDigitalLibrariesAutonomous1999,
  title = {Digital Libraries and Autonomous Citation Indexing},
  volume = {32},
  issn = {0018-9162},
  abstract = {The revolution the Web has brought to information dissemination is not so much due to the availability of data-huge amounts of information has long been available in libraries-but rather the improved efficiency of accessing (improved accessibility to) that information. The Web promises to make more scientific articles more easily available. By making the context of citations easily and quickly browsable, autonomous citation indexing can help to evaluate the importance of individual contributions more accurately and quickly. Digital libraries incorporating ACI can help organize scientific literature and may significantly improve the efficiency of dissemination and feedback. ACI may also help speed the transition to scholarly electronic publishing.},
  number = {6},
  journal = {Computer},
  doi = {10.1109/2.769447},
  author = {Lawrence, S. and Giles, C. Lee and Bollacker, K.},
  month = jun,
  year = {1999},
  keywords = {Citation analysis,accessibility,ACI,autonomous citation indexing,citation analysis,Databases,digital libraries,dissemination,electronic publishing,indexing,Indexing,information dissemination,Information retrieval,Internet,Joining processes,Navigation,Page description languages,scholarly electronic publishing,scientific articles,scientific literature,Search engines,Software libraries,Web,Web search},
  pages = {67-71},
  file = {/home/stephan/Zotero/storage/5VD7X68I/Lawrence et al. - 1999 - Digital libraries and autonomous citation indexing.pdf;/home/stephan/Zotero/storage/3UAM96R6/769447.html}
}

@inproceedings{carvalhoSemanticSoftwareMetadata2018,
  title = {Semantic {{Software Metadata}} for {{Workflow Exploration}} and {{Evolution}}},
  abstract = {Scientific workflow management systems play a major role in the design, execution and documentation of computational experiments. However, they have limited support for managing workflow evolution and exploration because they lack rich metadata for the software that implements workflow components. Such metadata could be used to support scientists in exploring local adjustments to a workflow, replacing components with similar software, or upgrading components upon release of newer software versions. To address this challenge, we propose OntoSoft-VFF (Ontology for Software Version, Function and Functionality), a software metadata repository designed to capture information about software and workflow components that is important for managing workflow exploration and evolution. Our approach uses a novel ontology to describe the functionality and evolution through time of any software used to create workflow components. OntoSoft-VFF is implemented as an online catalog that stores semantic metadata for software to enable workflow exploration through understanding of software functionality and evolution. The catalog also supports comparison and semantic search of software metadata. We showcase OntoSoft-VFF using machine learning workflow examples. We validate our approach by testing that a workflow system could compare differences in software metadata, explain software updates and describe the general functionality of workflow steps.},
  booktitle = {2018 {{IEEE}} 14th {{International Conference}} on E-{{Science}} (e-{{Science}})},
  doi = {10.1109/eScience.2018.00132},
  author = {Carvalho, L. A. M. C. and Garijo, D. and Medeiros, C. Bauzer and Gil, Y.},
  month = oct,
  year = {2018},
  keywords = {Metadata,Semantics,Software,software metadata,software registries,software engineering,Decision trees,Machine learning algorithms,machine learning workflow,meta data,ontologies (artificial intelligence),ontology for software version function and functionality,OntoSoft-VFF,scientific workflow management systems,scientific workflows,semantic metadata,semantic software metadata,Software algorithms,software functionality,software functions,software metadata repository,software updates,Task analysis,workflow components,workflow evolution,workflow exploration,workflow management software,workflow steps,workflow system},
  pages = {431-441},
  file = {/home/stephan/Zotero/storage/7CTA9CK4/Carvalho et al. - 2018 - Semantic Software Metadata for Workflow Exploratio.pdf;/home/stephan/Zotero/storage/ZBUFR88D/8588751.html}
}

@article{PersistentIdentifiersScholarly,
  title = {Persistent {{Identifiers}} for {{Scholarly Assets}} and the {{Web}}: {{The Need}} for an {{Unambiguous Mapping}} | {{International Journal}} of {{Digital Curation}}},
  shorttitle = {Persistent {{Identifiers}} for {{Scholarly Assets}} and the {{Web}}},
  language = {en-US},
  urldate = {2019-08-12},
  url = {http://www.ijdc.net/article/view/9.1.331},
  keywords = {curation,DCC,digital curation,digital preservation,IJDC,International Journal of Digital Curation,preservation},
  file = {/home/stephan/Zotero/storage/5LSD2TGE/Persistent Identifiers for Scholarly Assets and th.pdf;/home/stephan/Zotero/storage/UXSDDAT9/9.1.html}
}

@article{piwowarAltmetricsValueAll2013,
  title = {Altmetrics: {{Value}} All Research Products},
  volume = {493},
  copyright = {2013 Nature Publishing Group},
  issn = {1476-4687},
  shorttitle = {Altmetrics},
  abstract = {A new funding policy by the US National Science Foundation represents a sea-change in how researchers are evaluated, says Heather Piwowar.},
  language = {en},
  urldate = {2019-08-12},
  journal = {Nature},
  url = {https://www.nature.com/articles/493159a},
  author = {Piwowar, Heather},
  month = jan,
  year = {2013},
  pages = {159-159},
  file = {/home/stephan/Zotero/storage/T67WKFYP/Piwowar - 2013 - Altmetrics Value all research products.pdf;/home/stephan/Zotero/storage/QW3E5UKV/493159a.html}
}

@article{bechhoferResearchObjectsExchange2010,
  title = {Research {{Objects}}: {{Towards Exchange}} and {{Reuse}} of {{Digital Knowledge}}},
  copyright = {2010 Sean Bechhofer, David De Roure, Matthew Gamble, Carole Goble, Iain Buchan},
  issn = {1756-0357},
  shorttitle = {Research {{Objects}}},
  abstract = {What will researchers be publishing in the future? Whilst there is little question that the Web will be the publication platform, as scholars move away from paper towards digital content, there is a need for mechanisms that support the production of self-contained units of knowledge and facilitate the publication, sharing and reuse of such entities. In this paper we discuss the notion of \_research objects\_, semantically rich aggregations of resources, that can possess some scientific intent or support some research objective. We present a number of principles that we expect such objects and their associated services to follow.},
  language = {en},
  urldate = {2019-08-12},
  journal = {Nature Precedings},
  url = {https://www.nature.com/articles/npre.2010.4626.1},
  author = {Bechhofer, Sean and Roure, David De and Gamble, Matthew and Goble, Carole and Buchan, Iain},
  month = jul,
  year = {2010},
  pages = {1-1},
  file = {/home/stephan/Zotero/storage/2UXGX9QZ/Bechhofer et al. - 2010 - Research Objects Towards Exchange and Reuse of Di.pdf;/home/stephan/Zotero/storage/PLUWJJ2R/npre.2010.4626.html}
}

@article{belhajjameWorkflowCentricResearchObjects,
  title = {Workflow-{{Centric Research Objects}}: {{First Class Citizens}} in {{Scholarly Discourse}}},
  abstract = {A workflow-centric research object bundles a workflow, the provenance of the results obtained by its enactment, other digital objects that are relevant for the experiment (papers, datasets, etc.), and annotations that semantically describe all these objects. In this paper, we propose a model to specify workflow-centric research objects, and show how the model can be grounded using semantic technologies and existing vocabularies, in particular the Object Reuse and Exchange (ORE) model and the Annotation Ontology (AO). We describe the life-cycle of a research object, which resembles the life-cycle of a scientific experiment.},
  language = {en},
  author = {Belhajjame, Khalid and Corcho, Oscar and Garijo, Daniel and Zhao, Jun and Newman, David and Palma, Raul and Bechhofer, Sean and Garc\i{}a, Esteban and {Gomez-Perez}, Jose Manuel and Klyne, Graham and Page, Kevin and Ruiz, Jose Enrique and {Soiland-Reyes}, Stian and Roure, David De and Goble, Carole A},
  pages = {12},
  file = {/home/stephan/Zotero/storage/ERHAZIMG/Belhajjame et al. - Workﬂow-Centric Research Objects First Class Citi.pdf}
}

@article{shottonCiTOCitationTyping2010,
  title = {{{CiTO}}, the {{Citation Typing Ontology}}},
  volume = {1},
  issn = {2041-1480},
  abstract = {CiTO, the Citation Typing Ontology, is an ontology for describing the nature of reference citations in scientific research articles and other scholarly works, both to other such publications and also to Web information resources, and for publishing these descriptions on the Semantic Web. Citation are described in terms of the factual and rhetorical relationships between citing publication and cited publication, the in-text and global citation frequencies of each cited work, and the nature of the cited work itself, including its publication and peer review status. This paper describes CiTO and illustrates its usefulness both for the annotation of bibliographic reference lists and for the visualization of citation networks. The latest version of CiTO, which this paper describes, is CiTO Version 1.6, published on 19 March 2010. CiTO is written in the Web Ontology Language OWL, uses the namespace http://purl.org/net/cito/, and is available from http://purl.org/net/cito/. This site uses content negotiation to deliver to the user an OWLDoc Web version of the ontology if accessed via a Web browser, or the OWL ontology itself if accessed from an ontology management tool such as Prot{\'e}g{\'e} 4 (http://protege.stanford.edu/). Collaborative work is currently under way to harmonize CiTO with other ontologies describing bibliographies and the rhetorical structure of scientific discourse.},
  number = {1},
  urldate = {2019-08-12},
  journal = {Journal of Biomedical Semantics},
  url = {https://doi.org/10.1186/2041-1480-1-S1-S6},
  author = {Shotton, David},
  month = jun,
  year = {2010},
  pages = {S6},
  file = {/home/stephan/Zotero/storage/B6DFKZDH/Shotton - 2010 - CiTO, the Citation Typing Ontology.pdf;/home/stephan/Zotero/storage/L59XCFLT/2041-1480-1-S1-S6.html}
}

@book{croninBibliometricsHarnessingMultidimensional2014,
  address = {{Cambridge, Massachusetts}},
  title = {Beyond Bibliometrics: Harnessing Multidimensional Indicators of Scholarly Impact},
  isbn = {978-0-262-52551-0 978-0-262-02679-6},
  lccn = {Z669.8 .B49 2014},
  shorttitle = {Beyond Bibliometrics},
  publisher = {{The MIT Press}},
  editor = {Cronin, Blaise and Sugimoto, Cassidy R.},
  year = {2014},
  keywords = {Bibliometrics,Bibliographical citations,Communication in learning and scholarship,Evaluation,Evaluation Statistical methods,Research,Scholarly electronic publishing,Scholarly publishing,Scientific literature,Technological innovations}
}

@article{katzSoftwareCitationImplementation2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1905.08674},
  primaryClass = {cs},
  title = {Software {{Citation Implementation Challenges}}},
  copyright = {All rights reserved},
  abstract = {The main output of the FORCE11 Software Citation working group (https://www.force11.org/group/software-citation-working-group) was a paper on software citation principles (https://doi.org/10.7717/peerj-cs.86) published in September 2016. This paper laid out a set of six high-level principles for software citation (importance, credit and attribution, unique identification, persistence, accessibility, and specificity) and discussed how they could be used to implement software citation in the scholarly community. In a series of talks and other activities, we have promoted software citation using these increasingly accepted principles. At the time the initial paper was published, we also provided guidance and examples on how to make software citable, though we now realize there are unresolved problems with that guidance. The purpose of this document is to provide an explanation of current issues impacting scholarly attribution of research software, organize updated implementation guidance, and identify where best practices and solutions are still needed.},
  urldate = {2019-06-18},
  journal = {arXiv:1905.08674 [cs]},
  url = {http://arxiv.org/abs/1905.08674},
  author = {Katz, Daniel S. and Bouquin, Daina and Hong, Neil P. Chue and Hausman, Jessica and Jones, Catherine and Chivvis, Daniel and Clark, Tim and Crosas, Merc{\`e} and Druskat, Stephan and Fenner, Martin and Gillespie, Tom and {Gonzalez-Beltran}, Alejandra and Gruenpeter, Morane and Habermann, Ted and Haines, Robert and Harrison, Melissa and Henneken, Edwin and Hwang, Lorraine and Jones, Matthew B. and Kelly, Alastair A. and Kennedy, David N. and Leinweber, Katrin and Rios, Fernando and Robinson, Carly B. and Todorov, Ilian and Wu, Mingfang and Zhang, Qian},
  month = may,
  year = {2019},
  keywords = {Computer Science - Computers and Society,Computer Science - Digital Libraries},
  file = {/home/stephan/Zotero/storage/47W7PMSE/Katz et al. - 2019 - Software Citation Implementation Challenges.pdf;/home/stephan/Zotero/storage/3EA4ZPXV/1905.html}
}

@article{chidamberMetricsSuiteObject1994,
  title = {A Metrics Suite for Object Oriented Design},
  volume = {20},
  issn = {0098-5589},
  abstract = {Given the central role that software development plays in the delivery and application of information technology, managers are increasingly focusing on process improvement in the software development area. This demand has spurred the provision of a number of new and/or improved approaches to software development, with perhaps the most prominent being object-orientation (OO). In addition, the focus on process improvement has increased the demand for software measures, or metrics with which to manage the process. The need for such metrics is particularly acute when an organization is adopting a new technology for which established practices have yet to be developed. This research addresses these needs through the development and implementation of a new suite of metrics for OO design. Metrics developed in previous research, while contributing to the field's understanding of software development processes, have generally been subject to serious criticisms, including the lack of a theoretical base. Following Wand and Weber (1989), the theoretical base chosen for the metrics was the ontology of Bunge (1977). Six design metrics are developed, and then analytically evaluated against Weyuker's (1988) proposed set of measurement principles. An automated data collection tool was then developed and implemented to collect an empirical sample of these metrics at two field sites in order to demonstrate their feasibility and suggest ways in which managers may use these metrics for process improvement.{$<>$}},
  number = {6},
  journal = {IEEE Transactions on Software Engineering},
  doi = {10.1109/32.295895},
  author = {Chidamber, S. R. and Kemerer, C. F.},
  month = jun,
  year = {1994},
  keywords = {software development,Ontologies,Software engineering,Application software,automated data collection tool,Engineering management,Information management,Information technology,measurement principles,metrics suite,object oriented design,object oriented programming,object-oriented methods,object-oriented programming,organization,process improvement,Programming,Software development management,Software measurement,software measures,software metrics,Technology management},
  pages = {476-493},
  file = {/home/stephan/Zotero/storage/Y95NNNV7/295895.html}
}

@book{halsteadElementsSoftwareScience1979,
  address = {{New York, N.Y}},
  title = {Elements of Software Science},
  isbn = {978-0-444-00205-1},
  language = {English},
  publisher = {{North-Holland}},
  author = {Halstead, Maurice H},
  year = {1979},
  note = {OCLC: 885149327}
}

@misc{internationalcommitteeofmedicaljournaleditorsICMJERecommendationsDefining,
  title = {{{ICMJE Recommendations}}: {{Defining}} the {{Role}} of {{Authors}} and {{Contributors}}},
  urldate = {2019-05-10},
  url = {http://web.archive.org/web/20190905080833/http://www.icmje.org/recommendations/browse/roles-and-responsibilities/defining-the-role-of-authors-and-contributors.html\#two},
  author = {{International Committee of Medical Journal Editors}},
  file = {/home/stephan/Zotero/storage/JVMPKVMK/defining-the-role-of-authors-and-contributors.html}
}

@article{brandAuthorshipAttributionContribution2015,
  title = {Beyond Authorship: Attribution, Contribution, Collaboration, and Credit},
  volume = {28},
  issn = {1741-4857},
  shorttitle = {Beyond Authorship},
  abstract = {Key points As the number of authors on scientific publications increases, ordered lists of author names are proving inadequate for the purposes of attribution and credit. A multi-stakeholder group has produced a contributor role taxonomy for use in scientific publications. Identifying specific contributions to published research will lead to appropriate credit, fewer author disputes, and fewer disincentives to collaboration and the sharing of data and code.},
  language = {en},
  number = {2},
  urldate = {2019-05-10},
  journal = {Learned Publishing},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1087/20150211},
  author = {Brand, Amy and Allen, Liz and Altman, Micah and Hlava, Marjorie and Scott, Jo},
  year = {2015},
  pages = {151-155},
  file = {/home/stephan/Zotero/storage/FCDZZMZW/Brand et al. - 2015 - Beyond authorship attribution, contribution, coll.pdf;/home/stephan/Zotero/storage/Z9XP9WJM/20150211.html}
}

@inproceedings{hannayHowScientistsDevelop2009,
  title = {How Do Scientists Develop and Use Scientific Software?},
  abstract = {New knowledge in science and engineering relies increasingly on results produced by scientific software. Therefore, knowing how scientists develop and use software in their research is critical to assessing the necessity for improving current development practices and to making decisions about the future allocation of resources. To that end, this paper presents the results of a survey conducted online in October-December 2008 which received almost 2000 responses. Our main conclusions are that (1) the knowledge required to develop and use scientific software is primarily acquired from peers and through self-study, rather than from formal education and training; (2) the number of scientists using supercomputers is small compared to the number using desktop or intermediate computers; (3) most scientists rely primarily on software with a large user base; (4) while many scientists believe that software testing is important, a smaller number believe they have sufficient understanding about testing concepts; and (5) that there is a tendency for scientists to rank standard software engineering concepts higher if they work in large software development projects and teams, but that there is no uniform trend of association between rank of importance of software engineering concepts and project/team size.},
  booktitle = {2009 {{ICSE Workshop}} on {{Software Engineering}} for {{Computational Science}} and {{Engineering}}},
  doi = {10.1109/SECSE.2009.5069155},
  author = {Hannay, J. E. and MacLeod, C. and Singer, J. and Langtangen, H. P. and Pfahl, D. and Wilson, G.},
  month = may,
  year = {2009},
  keywords = {Software testing,scientific software,software engineering,Software engineering,Automatic testing,Computer science education,Knowledge engineering,Peer to peer computing,Resource management,scientific information systems,software development projects,Software standards,software testing,Standards development,supercomputers,Supercomputers},
  pages = {1-8},
  file = {/home/stephan/Zotero/storage/EIEEYZGW/5069155.html}
}

@article{piccoloToolsTechniquesComputational2016,
  title = {Tools and Techniques for Computational Reproducibility},
  volume = {5},
  issn = {2047-217X},
  abstract = {When reporting research findings, scientists document the steps they followed so that others can verify and build upon the research. When those steps have been described in sufficient detail that others can retrace the steps and obtain similar results, the research is said to be reproducible. Computers play a vital role in many research disciplines and present both opportunities and challenges for reproducibility. Computers can be programmed to execute analysis tasks, and those programs can be repeated and shared with others. The deterministic nature of most computer programs means that the same analysis tasks, applied to the same data, will often produce the same outputs. However, in practice, computational findings often cannot be reproduced because of complexities in how software is packaged, installed, and executed\textemdash{}and because of limitations associated with how scientists document analysis steps. Many tools and techniques are available to help overcome these challenges; here we describe seven such strategies. With a broad scientific audience in mind, we describe the strengths and limitations of each approach, as well as the circumstances under which each might be applied. No single strategy is sufficient for every scenario; thus we emphasize that it is often useful to combine approaches.},
  urldate = {2019-05-09},
  journal = {GigaScience},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4940747/},
  author = {Piccolo, Stephen R. and Frampton, Michael B.},
  month = jul,
  year = {2016},
  file = {/home/stephan/Zotero/storage/MDRFZY29/Piccolo and Frampton - 2016 - Tools and techniques for computational reproducibi.pdf},
  pmid = {27401684},
  pmcid = {PMC4940747}
}

@techreport{katzSoftwareVsData2016,
  title = {Software vs. Data in the Context of Citation},
  abstract = {Software is data, but it is not just data. While "data" in computing and information science can refer to anything that can be processed by a computer, software is a special kind of data that can be a creative, executable tool that operates on data. However, software and data are similar in that they both traditionally have not been cited in publications. This paper discusses the differences between software and data in the context of citation, by providing examples and referring to evidence in the form of citations.},
  language = {en},
  number = {e2630v1},
  urldate = {2019-05-09},
  institution = {{PeerJ Inc.}},
  url = {https://peerj.com/preprints/2630},
  author = {Katz, Daniel S. and Niemeyer, Kyle E. and Smith, Arfon M. and Anderson, William L. and Boettiger, Carl and Hinsen, Konrad and Hooft, Rob and Hucka, Michael and Lee, Allen and L{\"o}ffler, Frank and Pollard, Tom and Rios, Fernando},
  month = dec,
  year = {2016},
  file = {/home/stephan/Zotero/storage/HXU36HYX/Katz et al. - 2016 - Software vs. data in the context of citation.pdf;/home/stephan/Zotero/storage/L7H8VJHK/2630.html},
  doi = {10.7287/peerj.preprints.2630v1}
}

@article{chunSoftwarePersistenceVisual2005,
  title = {On {{Software}}, or the {{Persistence}} of {{Visual Knowledge}}},
  volume = {18},
  issn = {1526-3819},
  urldate = {2019-05-09},
  journal = {Grey Room},
  url = {https://www.mitpressjournals.org/doi/10.1162/1526381043320741},
  author = {Chun, Wendy Hui Kyong},
  month = jan,
  year = {2005},
  pages = {26-51},
  file = {/home/stephan/Zotero/storage/4M6QJFDA/Chun - 2005 - On Software, or the Persistence of Visual Knowledg.pdf;/home/stephan/Zotero/storage/GL7CDI6X/1526381043320741.html}
}

@book{cormenIntroductionAlgorithms2014,
  title = {Introduction to {{Algorithms}}},
  isbn = {978-0-262-53305-8},
  language = {English},
  author = {Cormen, Thomas H and Leiserson, Charles E and Rivest, Ronald L},
  year = {2014},
  note = {OCLC: 1020553375}
}

@article{plaleSoftwareScienceReport,
  title = {Software in {{Science}}: A {{Report}} of {{Outcomes}} of the 2014 {{National Science Foundation Software Infrastructure}} for {{Sustained Innovation}} ({{SI2}}) {{Meeting}}},
  abstract = {The second annual NSF Software Infrastructure for Sustained Innovation (SI2) PI meeting took place in Arlington, VA February 24-25, 2014. It was hosted by Beth Plale, Indiana University; Douglas Thain, University of Notre Dame; and Matt Jones, National Center for Ecological Analysis and Synthesis.},
  language = {en},
  url = {http://ccl.cse.nd.edu/research/papers/software-nsf-2014.pdf},
  author = {Plale, Beth and Jones, Matt and Thain, Douglas},
  pages = {8},
  file = {/home/stephan/Zotero/storage/YTA376SH/Plale et al. - Software in Science a Report of Outcomes of the 2.pdf}
}

@article{liHowCitedResearch2017,
  title = {How Is {{R}} Cited in Research Outputs? {{Structure}}, Impacts, and Citation Standard},
  volume = {11},
  issn = {1751-1577},
  shorttitle = {How Is {{R}} Cited in Research Outputs?},
  abstract = {This paper addresses software citation by analyzing how R and its packages are cited in a sample of PLoS papers. A codebook is developed to support a content analysis of the full-text papers. Our results indicate that the software R and its packages are inconsistently cited, as is the case with other scientific software. The inconsistency derives partly from the variety of citation standards currently used for software, and partly from fact that these standards are not well followed by authors on multiple levels. This work sheds light on the future development of software citation standards, especially given the present landscape of conflicting citation practices. Moreover, our approach furnishes a possible blueprint for dealing with the granularity of software entities in scientific citation: we consider citations of the core R software environment, of specific R packages, and of individual functions.},
  number = {4},
  urldate = {2019-05-08},
  journal = {Journal of Informetrics},
  url = {http://www.sciencedirect.com/science/article/pii/S1751157717300329},
  author = {Li, Kai and Yan, Erjia and Feng, Yuanyuan},
  month = nov,
  year = {2017},
  keywords = {Bibliometrics,Software citation,Scholarly communication,Content analysis,R},
  pages = {989-1002},
  file = {/home/stephan/Zotero/storage/X75P2PKL/Li et al. - 2017 - How is R cited in research outputs Structure, imp.pdf;/home/stephan/Zotero/storage/KLYGZ3F8/S1751157717300329.html}
}

@article{liChallengesMeasuringSoftware2019,
  title = {Challenges of Measuring Software Impact through Citations: {{An}} Examination of the Lme4 {{R}} Package},
  volume = {13},
  issn = {1751-1577},
  shorttitle = {Challenges of Measuring Software Impact through Citations},
  abstract = {The rise of software as a research object is mirrored by increasing interests in quantitative studies of scientific software. However, inconsistent citation practices have led most existing studies of this type to base their analysis of software impact on software name mentions, as identified in full-text publications. Despite its limitations, citation data exists in much greater quantities and covers a broader array of scientific fields than full-text data, and thus can support investigations with much wider scope. This paper aims to analyze the extent to which citation data can be used to reconstruct the impact of software. Specifically, we identify the variety of citable objects related to the lme4 R package and examine how the package's impact is dispersed across these objects. Our results shed light on a little-discussed challenge of using citation data to measure software impact: even within the category of formal citation, the same software object might be cited in different forms. We consider the implications of this challenge and propose a method to reconstruct the impact of lme4 through its citations nonetheless.},
  number = {1},
  urldate = {2019-05-08},
  journal = {Journal of Informetrics},
  url = {http://www.sciencedirect.com/science/article/pii/S1751157718304796},
  author = {Li, Kai and Chen, Pei-Ying and Yan, Erjia},
  month = feb,
  year = {2019},
  keywords = {Software citation,Citable object,lme4},
  pages = {449-461},
  file = {/home/stephan/Zotero/storage/KU66IBM4/Li et al. - 2019 - Challenges of measuring software impact through ci.pdf;/home/stephan/Zotero/storage/WL9E35R8/S1751157718304796.html}
}

@article{parkResearchSoftwareCitation2019,
  title = {Research Software Citation in the {{Data Citation Index}}: {{Current}} Practices and Implications for Research Software Sharing and Reuse},
  volume = {13},
  issn = {1751-1577},
  shorttitle = {Research Software Citation in the {{Data Citation Index}}},
  abstract = {The aim of this study is to explore the phenomenon of research software citation and, in particular, to draw attention to the increasing importance of this form of citation in scholarly communication. This research sheds light on the current status of formal software citation that is captured by citation databases. Data for the study were gathered from more than 67,000 research software records available in public repositories indexed by Clarivate Analytics' Data Citation Index (DCI). The metadata characteristics of the indexed records and citation data were then analyzed. Research software was rarely cited in the DCI, suggesting that the documented reuse of research software rarely occurs or is not well documented. Institutional repositories attracted few citations and had low rate of citation. It proved impossible, however, using the available data to isolate specific identifiers that can promote formal software citation. The findings presented here offer insights into research software citation that will be of interest to funding agencies, publishers, researchers, and research organizations.},
  number = {2},
  urldate = {2019-05-08},
  journal = {Journal of Informetrics},
  url = {http://www.sciencedirect.com/science/article/pii/S1751157718302372},
  author = {Park, Hyoungjoo and Wolfram, Dietmar},
  month = may,
  year = {2019},
  keywords = {Software citation,Research data,Research software,Software reuse,Software sharing},
  pages = {574-582},
  file = {/home/stephan/Zotero/storage/TDSHQ26E/Park_Wolfram_JOI_2019.pdf;/home/stephan/Zotero/storage/YKAMWAWU/S1751157718302372.html}
}

@article{katzTransitiveCreditMeans2014,
  title = {Transitive {{Credit}} as a {{Means}} to {{Address Social}} and {{Technological Concerns Stemming}} from {{Citation}} and {{Attribution}} of {{Digital Products}}},
  volume = {2},
  copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are \textcopyright, \textregistered{} or \texttrademark{} of their respective owners. No challenge to any owner's rights is intended or should be inferred.},
  issn = {2049-9647},
  abstract = {The pursuit of science and engineering research increasingly relies on activities that facilitate research but are not currently rewarded or recognized, such as development of products and infrastructure. In research publications, citations are used to credit previous works. This paper suggests that a modified citation system that includes the technological idea of transient credit could be used to recognize the developers of products other than research publications and that if this were done in a systematic manner, it would lead to social and cultural changes that would provide incentives for the further development of such products, accelerating overall scientific and engineering advances.},
  language = {en},
  number = {1},
  urldate = {2019-05-08},
  journal = {Journal of Open Research Software},
  url = {http://doi.org/10.5334/jors.be},
  author = {Katz, Daniel},
  month = jul,
  year = {2014},
  keywords = {attribution,citation,credit,software},
  pages = {e20},
  file = {/home/stephan/Zotero/storage/A6JJ4LW8/Katz - 2014 - Transitive Credit as a Means to Address Social and.pdf;/home/stephan/Zotero/storage/HLQ64K73/Katz - 2014 - Transitive Credit as a Means to Address Social and.pdf;/home/stephan/Zotero/storage/R4778VMU/jors.html;/home/stephan/Zotero/storage/RJBJ4IMP/jors.html},
  ids = {katzTransitiveCreditMeans2014}
}

@article{abramaticBuildingUniversalArchive2018,
  title = {Building the {{Universal Archive}} of {{Source Code}}},
  volume = {61},
  issn = {0001-0782},
  abstract = {A global collaborative project for the benefit of all.},
  number = {10},
  urldate = {2019-05-08},
  journal = {Commun. ACM},
  url = {http://doi.acm.org/10.1145/3183558},
  author = {Abramatic, Jean-Fran{\c c}ois and Di Cosmo, Roberto and Zacchiroli, Stefano},
  month = sep,
  year = {2018},
  pages = {29--31},
  file = {/home/stephan/Zotero/storage/A6EL4M83/Abramatic et al. - 2018 - Building the Universal Archive of Source Code.pdf}
}

@misc{JournalOpenResearch,
  title = {Journal of {{Open Research Software}}},
  abstract = {The Journal of Open Research Software (JORS) features peer reviewed Software Metapapers describing research software with high reuse potential. We are working with a number of specialist and institutional repositories to ensure that the associated software is professionally archived, preserved, and is openly available. Equally importantly, the software and the papers will be citable, and reuse will be tracked.JORS also publishes full-length research papers that cover different aspects of creating, maintaining and evaluating open source research software. The aim of the section is to promote the dissemination of best practice and experience related to the development and maintenance of reusable, sustainable research software.},
  language = {en},
  urldate = {2019-05-08},
  url = {http://openresearchsoftware.metajnl.com/},
  file = {/home/stephan/Zotero/storage/EU2AY6FT/openresearchsoftware.metajnl.com.html}
}

@article{smithJournalOpenSource2018,
  title = {Journal of {{Open Source Software}} ({{JOSS}}): Design and First-Year Review},
  volume = {4},
  issn = {2376-5992},
  shorttitle = {Journal of {{Open Source Software}} ({{JOSS}})},
  abstract = {This article describes the motivation, design, and progress of the Journal of Open Source Software (JOSS). JOSS is a free and open-access journal that publishes articles describing research software. It has the dual goals of improving the quality of the software submitted and providing a mechanism for research software developers to receive credit. While designed to work within the current merit system of science, JOSS addresses the dearth of rewards for key contributions to science made in the form of software. JOSS publishes articles that encapsulate scholarship contained in the software itself, and its rigorous peer review targets the software components: functionality, documentation, tests, continuous integration, and the license. A JOSS article contains an abstract describing the purpose and functionality of the software, references, and a link to the software archive. The article is the entry point of a JOSS submission, which encompasses the full set of software artifacts. Submission and review proceed in the open, on GitHub. Editors, reviewers, and authors work collaboratively and openly. Unlike other journals, JOSS does not reject articles requiring major revision; while not yet accepted, articles remain visible and under review until the authors make adequate changes (or withdraw, if unable to meet requirements). Once an article is accepted, JOSS gives it a digital object identifier (DOI), deposits its metadata in Crossref, and the article can begin collecting citations on indexers like Google Scholar and other services. Authors retain copyright of their JOSS article, releasing it under a Creative Commons Attribution 4.0 International License. In its first year, starting in May 2016, JOSS published 111 articles, with more than 40 additional articles under review. JOSS is a sponsored project of the nonprofit organization NumFOCUS and is an affiliate of the Open Source Initiative (OSI).},
  language = {en},
  urldate = {2019-05-08},
  journal = {PeerJ Computer Science},
  url = {https://peerj.com/articles/cs-147},
  author = {Smith, Arfon M. and Niemeyer, Kyle E. and Katz, Daniel S. and Barba, Lorena A. and Githinji, George and Gymrek, Melissa and Huff, Kathryn D. and Madan, Christopher R. and Mayes, Abigail Cabunoc and Moerman, Kevin M. and Prins, Pjotr and Ram, Karthik and Rokem, Ariel and Teal, Tracy K. and Guimera, Roman Valls and Vanderplas, Jacob T.},
  month = feb,
  year = {2018},
  pages = {e147},
  file = {/home/stephan/Zotero/storage/M8RWAQI5/Smith et al. - 2018 - Journal of Open Source Software (JOSS) design and.pdf;/home/stephan/Zotero/storage/ID7SL5G5/cs-147.html}
}

@article{druskat_stephan_2018_1405679,
  title = {Citation {{File Format}} ({{CFF}})},
  url = {https://doi.org/10.5281/zenodo.1003149},
  author = {Druskat, Stephan and Spaaks, Jurriaan H. and Chue Hong, Neil and Haines, Robert and Baker, James},
  month = aug,
  year = {2018}
}

@article{17fab9192ca44c38a549b4dd5deb7a48,
  title = {{Lightning talk: Software citation: Process, principles, and implementation}},
  volume = {1686},
  issn = {1613-0073},
  abstract = {Software is a critical part of modern research and yet there is little support across the scholarly ecosystem for its acknowledgement and citation. Inspired by the activities of the FORCE11 working group focused on data citation, FORCE11 started a Software Citation Working Group (SCWG). The group initially sought members, and currently has about 55-60 members. The working group reviewed existing community practices, developed a set of use cases, and drafted a software citation principles document. This presentation will discuss the principles (in brief: importance, credit and attribution, unique identification, persistence, accessibility, and specificity), how they will impact the practice of research, and they can be implemented by researchers, publishers, librarians and others who build and maintain repositories, scholars of science, university administrators, and research funders. It should also spark discussion in Track 2 of WSSSPE4 about both the next steps related to software citation and the community goals related to software credit, reproducibility, and sustainability.},
  language = {English (US)},
  journal = {CEUR Workshop Proceedings},
  author = {{FORCE11 Software Citation Working Group} and Katz, Daniel S. and Niemeyer, Kyle E. and Katz, Daniel S},
  month = jan,
  year = {2016},
  day = {1}
}

@article{shottonSettingOurBibliographic2015,
  title = {Setting Our Bibliographic References Free: Towards Open Citation Data},
  volume = {71},
  issn = {0022-0418},
  shorttitle = {Setting Our Bibliographic References Free},
  number = {2},
  urldate = {2019-05-07},
  journal = {Journal of Documentation},
  url = {https://www.emeraldinsight.com/doi/full/10.1108/JD-12-2013-0166},
  author = {Shotton, David and Dutton, Alexander and Peroni, Silvio and Gray, Tanya},
  month = feb,
  year = {2015},
  keywords = {Citations,Open access,Open citation corpus,References,Semantic publishing,SPAR ontologies},
  pages = {253-277},
  file = {/home/stephan/Zotero/storage/WN7WZIS4/Shotton et al. - 2015 - Setting our bibliographic references free towards.pdf;/home/stephan/Zotero/storage/UQTERBY2/JD-12-2013-0166.html}
}

@inproceedings{anCitationMetadataExtraction2017,
  address = {{New York, NY, USA}},
  series = {{{CIKM}} '17},
  title = {Citation {{Metadata Extraction}} via {{Deep Neural Network}}-Based {{Segment Sequence Labeling}}},
  isbn = {978-1-4503-4918-5},
  abstract = {Citation metadata extraction plays an important role in academic information retrieval and knowledge management. Current works on this task generally use rule-based, template-based or learning-based approaches but these methods usually either rely on handcrafted features or are limited with domains. Recently, neural networks have shown strong ability in addressing sequence labeling tasks. In this paper, we propose a sequence labeling model for citation metadata extraction, called segment sequence labeling. Instead of inferring at word level, the input sequence is first divided into segments, and then features of the segments are computed to infer the label sequence of the segments. We first run experiments to validate the effectiveness of different parts of the model by comparing it with a CRF-based model and a neural network-based model. Experimental results show our model beats both models on most fields. Besides, our model is evaluated on public datasets UMass and Cora and has achieved significant performance improvement. Our model was trained on the data which were generated from BibTeX files collected on the Web and annotated automatically.},
  urldate = {2019-05-07},
  booktitle = {Proceedings of the 2017 {{ACM}} on {{Conference}} on {{Information}} and {{Knowledge Management}}},
  publisher = {{ACM}},
  url = {http://doi.acm.org/10.1145/3132847.3133074},
  author = {An, Dong and Gao, Liangcai and Jiang, Zhuoren and Liu, Runtao and Tang, Zhi},
  year = {2017},
  keywords = {information retrieval,academic information extraction,citation metadata extraction,sequence labeling},
  pages = {1967--1970},
  file = {/home/stephan/Zotero/storage/CAPVEW6W/An et al. - 2017 - Citation Metadata Extraction via Deep Neural Netwo.pdf}
}

@article{nasarInformationExtractionScientific2018,
  title = {Information Extraction from Scientific Articles: A Survey},
  volume = {117},
  issn = {1588-2861},
  shorttitle = {Information Extraction from Scientific Articles},
  abstract = {In last few decades, with the advent of World Wide Web (WWW), world is being overloaded with huge data. This huge data carries potential information that once extracted, can be used for betterment of humanity. Information from this data can be extracted using manual and automatic analysis. Manual analysis is not scalable and efficient, whereas, the automatic analysis involves computing mechanisms that aid in automatic information extraction over huge amount of data. WWW has also affected overall growth in scientific literature that makes the process of literature review quite laborious, time consuming and cumbersome job for researchers. Hence a dire need is felt to automatically extract potential information out of immense set of scientific articles to automate the process of literature review. Therefore, in this study, aim is to present the overall progress concerning automatic information extraction from scientific articles. The information insights extracted from scientific articles are classified in two broad categories i.e. metadata and key-insights. As available benchmark datasets carry a significant role in overall development in this research domain, existing datasets against both categories are extensively reviewed. Later, research studies in literature that have applied various computational approaches applied on these datasets are consolidated. Major computational approaches in this regard include Rule-based approaches, Hidden Markov Models, Conditional Random Fields, Support Vector Machines, Na{\"i}ve-Bayes classification and Deep Learning approaches. Currently, there are multiple projects going on that are focused towards the dataset construction tailored to specific information needs from scientific articles. Hence, in this study, state-of-the-art regarding information extraction from scientific articles is covered. This study also consolidates evolving datasets as well as various toolkits and code-bases that can be used for information extraction from scientific articles.},
  language = {en},
  number = {3},
  urldate = {2019-05-07},
  journal = {Scientometrics},
  url = {https://doi.org/10.1007/s11192-018-2921-5},
  author = {Nasar, Zara and Jaffry, Syed Waqar and Malik, Muhammad Kamran},
  month = dec,
  year = {2018},
  keywords = {Scientific literature,Information extraction,Key-insights extraction,Machine learning,Metadata extraction,Research articles,Text mining},
  pages = {1931-1990},
  file = {/home/stephan/Zotero/storage/KBLHNFLR/Nasar et al. - 2018 - Information extraction from scientific articles a.pdf}
}

@inproceedings{guoReferenceMetadataExtraction2011,
  title = {Reference Metadata Extraction from Scientific Papers},
  abstract = {Bibliographical information of scientific papers is of great value since the Science Citation Index is introduced to measure research impact. Most scientific documents available on the web are unstructured or semi-structured, and the automatic reference metadata extraction process becomes an important task. This paper describes a framework for automatic reference metadata extraction from scientific papers. Our system can extract title, author, journal, volume, year, and page from scientific papers in PDF. We utilize a document metadata knowledge base to guide the reference metadata extraction process. The experiment results show that our system achieves a high accuracy.},
  booktitle = {2011 12th {{International Conference}} on {{Parallel}} and {{Distributed Computing}}, {{Applications}} and {{Technologies}}},
  doi = {10.1109/PDCAT.2011.72},
  author = {Guo, Z. and Jin, H.},
  month = oct,
  year = {2011},
  keywords = {Semantics,citation analysis,Internet,Web,meta data,Data mining,information retrieval,Accuracy,automatic reference metadata extraction process,Bibliographical Information,document handling,document metadata knowledge base,Hidden Markov models,knowledge based systems,Knowledge based systems,Libraries,metadata extraction,natural sciences computing,Portable document format,reference,rule-based approach,science citation index,scientific documents,scientific papers,semistructured metadata extraction process,unstructured metadata extraction process},
  pages = {45-49},
  file = {/home/stephan/Zotero/storage/7ZH6ZSIB/Guo und Jin - 2011 - Reference metadata extraction from scientific pape.pdf;/home/stephan/Zotero/storage/EJZPWBPE/6118965.html}
}

@article{gobleBetterSoftwareBetter2014,
  title = {Better {{Software}}, {{Better Research}}},
  volume = {18},
  issn = {1089-7801},
  abstract = {Modern scientific research isn't possible without software. However, its vital role is often overlooked by funders, universities, assessment committees, and even the research community itself. This is a serious issue that needs urgent attention. This article raises a number of points concerning quality, code review, and openness; development practices and training in scientific computing; career recognition of research software engineers; and sustainability models for funding scientific software. We must get software recognized to be the first-class experimental scientific instrument that it is and get "better software for better research."},
  number = {5},
  journal = {IEEE Internet Computing},
  doi = {10.1109/MIC.2014.88},
  author = {Goble, C.},
  month = sep,
  year = {2014},
  keywords = {scientific software,sustainability,engineering},
  pages = {4-8},
  file = {/home/stephan/Zotero/storage/RWIGL3VN/Goble - 2014 - Better Software, Better Research.pdf;/home/stephan/Zotero/storage/MT7MBYN9/6886129.html}
}

@article{katzTransitiveCreditJSONLD2015,
  title = {Transitive {{Credit}} and {{JSON}}-{{LD}}},
  volume = {3},
  copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are \textcopyright, \textregistered{} or \texttrademark{} of their respective owners. No challenge to any owner's rights is intended or should be inferred.},
  issn = {2049-9647},
  abstract = {Science and engineering research increasingly relies on activities that facilitate research but are not currently rewarded or recognized, such as: data sharing; developing common data resources, software and methodologies; and annotating data and publications. To promote and advance these activities, we must develop mechanisms for assigning credit, facilitate the appropriate attribution of research outcomes, devise incentives for activities that facilitate research, and allocate funds to maximize return on investment. In this article, we focus on addressing the issue of assigning credit for both direct and indirect contributions, specifically by using JSON-LD to implement a prototype transitive credit system.},
  language = {en},
  number = {1},
  urldate = {2019-04-12},
  journal = {Journal of Open Research Software},
  url = {http://openresearchsoftware.metajnl.com/articles/10.5334/jors.by/},
  author = {Katz, Daniel S. and Smith, Arfon M.},
  month = nov,
  year = {2015},
  keywords = {attribution,credit,open science,scholarly products},
  pages = {e7},
  file = {/home/stephan/Zotero/storage/C67PY392/Katz and Smith - 2015 - Transitive Credit and JSON-LD.pdf;/home/stephan/Zotero/storage/DQ7BDV26/jors.html}
}

@article{smithSoftwareCitationPrinciples2016,
  title = {Software Citation Principles},
  volume = {2},
  issn = {2376-5992},
  number = {e86},
  journal = {PeerJ Computer Science},
  url = {https://doi.org/10.7717/peerj-cs.86},
  author = {Smith, Arfon M. and Katz, Daniel S. and Niemeyer, Kyle E. and {FORCE11 Software Citation Working Group}},
  year = {2016},
  file = {/home/stephan/Zotero/storage/MIA8UJBQ/Smith et al. - 2016 - Software citation principles.pdf;/home/stephan/Zotero/storage/QPG7HCLB/cs-86.html}
}

@article{borgmanScholarlyCommunicationBibliometrics2005,
  title = {Scholarly Communication and Bibliometrics},
  volume = {36},
  issn = {00664200},
  language = {en},
  number = {1},
  urldate = {2019-08-14},
  journal = {Annual Review of Information Science and Technology},
  url = {http://doi.wiley.com/10.1002/aris.1440360102},
  author = {Borgman, Christine L. and Furner, Jonathan},
  month = feb,
  year = {2005},
  pages = {2-72},
  file = {/home/stephan/Zotero/storage/4BAHLTKZ/Borgman and Furner - 2005 - Scholarly communication and bibliometrics.pdf}
}

@article{croninScholarlyCommunicationEpistemic2003,
  title = {Scholarly Communication and Epistemic Cultures},
  volume = {9},
  issn = {1361-4533},
  number = {1},
  urldate = {2019-08-14},
  journal = {New Review of Academic Librarianship},
  url = {https://doi.org/10.1080/13614530410001692004},
  author = {Cronin, Blaise},
  month = dec,
  year = {2003},
  pages = {1-24},
  file = {/home/stephan/Zotero/storage/THKTJDWP/Cronin - 2003 - Scholarly communication and epistemic cultures.pdf;/home/stephan/Zotero/storage/FUHDLTXC/13614530410001692004.html}
}

@article{garfieldCitationAnalysisTool1972,
  title = {Citation {{Analysis}} as a {{Tool}} in {{Journal Evaluation}}: {{Journals}} Can Be Ranked by Frequency and Impact of Citations for Science Policy Studies},
  volume = {178},
  copyright = {1972 by the American Association for the Advancement of Science},
  issn = {0036-8075, 1095-9203},
  shorttitle = {Citation {{Analysis}} as a {{Tool}} in {{Journal Evaluation}}},
  language = {en},
  number = {4060},
  urldate = {2019-08-14},
  journal = {Science},
  url = {https://science.sciencemag.org/content/178/4060/471},
  author = {Garfield, Eugene},
  month = nov,
  year = {1972},
  pages = {471-479},
  file = {/home/stephan/Zotero/storage/KXV4P7QX/Garfield - 1972 - Citation Analysis as a Tool in Journal Evaluation.pdf;/home/stephan/Zotero/storage/8FIVLPJ5/471.html},
  pmid = {5079701}
}

@book{debellisBibliometricsCitationAnalysis2009,
  address = {{Lanham, Md}},
  title = {Bibliometrics and Citation Analysis: From the {{Science}} Citation Index to Cybermetrics},
  isbn = {978-0-8108-6713-0 978-0-8108-6714-7},
  lccn = {Z669.8 D43 2009},
  shorttitle = {Bibliometrics and Citation Analysis},
  publisher = {{Scarecrow Press}},
  author = {De Bellis, Nicola},
  year = {2009},
  keywords = {Bibliometrics,Bibliographical citations,Scientific literature,Information science,Statistical methods,Technical literature},
  note = {OCLC: ocn268952958}
}

@book{gingrasBibliometricsResearchEvaluation2016,
  address = {{Cambridge, Massachusetts}},
  series = {History and Foundations of Information Science},
  title = {Bibliometrics and Research Evaluation: Uses and Abuses},
  isbn = {978-0-262-03512-5},
  lccn = {Q180.55.E9 G5613 2016},
  shorttitle = {Bibliometrics and Research Evaluation},
  language = {eng},
  publisher = {{The MIT Press}},
  author = {Gingras, Yves},
  year = {2016},
  keywords = {Bibliometrics,Evaluation,Research,Education; Higher,Research Evaluation,Universities and colleges}
}

@article{neumayer15YearsProtest2016,
  title = {15 {{Years}} of {{Protest}} and {{Media Technologies Scholarship}}: {{A Sociotechnical Timeline}}},
  volume = {2},
  issn = {2056-3051, 2056-3051},
  shorttitle = {15 {{Years}} of {{Protest}} and {{Media Technologies Scholarship}}},
  language = {en},
  number = {3},
  urldate = {2019-08-16},
  journal = {Social Media + Society},
  url = {http://journals.sagepub.com/doi/10.1177/2056305116662180},
  author = {Neumayer, Christina and Rossi, Luca},
  month = sep,
  year = {2016},
  pages = {205630511666218},
  file = {/home/stephan/Zotero/storage/NB3UE5DI/Neumayer and Rossi - 2016 - 15 Years of Protest and Media Technologies Scholar.pdf}
}

@book{foucaultArchaeologyKnowledge1982,
  address = {{New York, NY}},
  title = {The Archaeology of Knowledge},
  isbn = {978-0-394-71106-5},
  language = {eng},
  publisher = {{Pantheon Books}},
  author = {Foucault, Michel},
  year = {1982},
  file = {/home/stephan/Zotero/storage/5S5YY5BS/Foucault - 1982 - The archaeology of knowledge.pdf},
  note = {OCLC: 254102097}
}

@article{deutscheforschungsgemeinschaftdfgLeitlinienZurSicherung2019,
  title = {{Leitlinien zur Sicherung guter wissenschaftlicher Praxis (Kodex) [Guidelines for Safeguarding Good Scientific Practice (Code)]}},
  language = {de},
  url = {http://web.archive.org/web/20190903173540/https://www.dfg.de/download/pdf/foerderung/rechtliche_rahmenbedingungen/gute_wissenschaftliche_praxis/kodex_gwp.pdf},
  author = {Deutsche Forschungsgemeinschaft (DFG)},
  month = aug,
  year = {2019},
  pages = {32},
  file = {/home/stephan/Zotero/storage/P5ZZJC7B/Leitlinien zur Sicherung guter wissenschaftlicher .pdf}
}

@incollection{deutscheforschungsgemeinschaftdfgSicherungGuterWissenschaftlicher2013,
  address = {{Weinheim, Germany}},
  title = {Sicherung Guter Wissenschaftlicher {{Praxis}}},
  isbn = {978-3-527-67918-8 978-3-527-33703-3},
  language = {en},
  urldate = {2019-08-16},
  booktitle = {Sicherung {{Guter Wissenschaftlicher Praxis}}},
  publisher = {{Wiley-VCH Verlag GmbH \& Co. KGaA}},
  url = {http://doi.wiley.com/10.1002/9783527679188.oth1},
  editor = {{Deutsche Forschungsgemeinschaft DFG}},
  month = oct,
  year = {2013},
  pages = {1-109},
  file = {/home/stephan/Zotero/storage/2YZ6LWF8/2013 - Sicherung guter wissenschaftlicher Praxis.pdf},
  doi = {10.1002/9783527679188.oth1}
}

@book{borgmanScholarshipDigitalAge2007,
  address = {{Cambridge, Mass}},
  title = {Scholarship in the Digital Age: Information, Infrastructure, and the {{Internet}}},
  isbn = {978-0-262-02619-2},
  lccn = {AZ195 .B67 2007},
  shorttitle = {Scholarship in the Digital Age},
  publisher = {{MIT Press}},
  author = {Borgman, Christine L.},
  year = {2007},
  keywords = {Communication in learning and scholarship,Scholarly electronic publishing,Technological innovations,Information technology,Learning and scholarship,Social aspects},
  note = {OCLC: ocm76794695}
}

@article{leydesdorffTextsContextsAdvances1999,
  title = {Between Texts and Contexts: {{Advances}} in Theories of Citation? ({{A}} Rejoinder)},
  volume = {44},
  issn = {1588-2861},
  shorttitle = {Between Texts and Contexts},
  abstract = {Scientific literature is expected to contain a body of knowledge that can be indexed and retrieved using references and citations. References are subtexts which refer to a supertext, that is, the body of scientific literature. TheScience Citation Index has provided an electronic representation of science at the supertextual level by aggregating the subtextual citations. As the supertext, however, becomes independently available in virtual reality (as a ``hypertext''), subtext and supertext become increasingly different contexts. The dynamics of hyperlinks are expected to feedback on the system of indexing, referencing, and retrieval at the level of research practices. References can be considered as part of the retention mechanism of this evolving system of scientific communication, and citations are a codified form of referencing.},
  language = {en},
  number = {2},
  urldate = {2019-08-19},
  journal = {Scientometrics},
  url = {https://doi.org/10.1007/BF02457378},
  author = {Leydesdorff, L. and Wouters, P.},
  month = feb,
  year = {1999},
  keywords = {Citation Analysis,Citation Context,Citation Window,Science Citation Index,Scientometric Indicator},
  pages = {169-182},
  file = {/home/stephan/Zotero/storage/U7KHGXZK/Leydesdorff and Wouters - 1999 - Between texts and contexts Advances in theories o.pdf}
}

@article{niemeyerChallengePromiseSoftware2016,
  title = {The {{Challenge}} and {{Promise}} of {{Software Citation}} for {{Credit}}, {{Identification}}, {{Discovery}}, and {{Reuse}}},
  volume = {7},
  issn = {1936-1955},
  number = {4},
  urldate = {2019-08-19},
  journal = {J. Data and Information Quality},
  url = {http://doi.acm.org/10.1145/2968452},
  author = {Niemeyer, Kyle E. and Smith, Arfon M. and Katz, Daniel S.},
  month = oct,
  year = {2016},
  keywords = {attribution,Software citation,software credit},
  pages = {16:1--16:5},
  file = {/home/stephan/Zotero/storage/JK37BM9E/Niemeyer et al. - 2016 - The Challenge and Promise of Software Citation for.pdf;/home/stephan/Zotero/storage/T8KTKLAZ/Niemeyer et al. - 2016 - The Challenge and Promise of Software Citation for.pdf},
  ids = {niemeyerChallengePromiseSoftware2016}
}

@article{kellyPeerReviewScientific2014,
  title = {Peer {{Review}} in {{Scientific Publications}}: {{Benefits}}, {{Critiques}}, \& {{A Survival Guide}}},
  volume = {25},
  issn = {1650-3414},
  shorttitle = {Peer {{Review}} in {{Scientific Publications}}},
  abstract = {Peer review has been defined as a process of subjecting an author's scholarly work, research or ideas to the scrutiny of others who are experts in the same field. It functions to encourage authors to meet the accepted high standards of their discipline and to control the dissemination of research data to ensure that unwarranted claims, unacceptable interpretations or personal views are not published without prior expert review. Despite its wide-spread use by most journals, the peer review process has also been widely criticised due to the slowness of the process to publish new findings and due to perceived bias by the editors and/or reviewers. Within the scientific community, peer review has become an essential component of the academic writing process. It helps ensure that papers published in scientific journals answer meaningful research questions and draw accurate conclusions based on professionally executed experimentation. Submission of low quality manuscripts has become increasingly prevalent, and peer review acts as a filter to prevent this work from reaching the scientific community. The major advantage of a peer review process is that peer-reviewed articles provide a trusted form of scientific communication. Since scientific knowledge is cumulative and builds on itself, this trust is particularly important. Despite the positive impacts of peer review, critics argue that the peer review process stifles innovation in experimentation, and acts as a poor screen against plagiarism. Despite its downfalls, there has not yet been a foolproof system developed to take the place of peer review, however, researchers have been looking into electronic means of improving the peer review process. Unfortunately, the recent explosion in online only/electronic journals has led to mass publication of a large number of scientific articles with little or no peer review. This poses significant risk to advances in scientific knowledge and its future potential. The current article summarizes the peer review process, highlights the pros and cons associated with different types of peer review, and describes new methods for improving peer review.},
  number = {3},
  urldate = {2019-08-19},
  journal = {EJIFCC},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4975196/},
  author = {Kelly, Jacalyn and Sadeghieh, Tara and Adeli, Khosrow},
  month = oct,
  year = {2014},
  pages = {227-243},
  file = {/home/stephan/Zotero/storage/NIA2ZB7W/Kelly et al. - 2014 - Peer Review in Scientific Publications Benefits, .pdf},
  pmid = {27683470},
  pmcid = {PMC4975196}
}

@article{mooneyCitingDataSources2011,
  title = {Citing Data Sources in the Social Sciences: Do Authors Do It?},
  volume = {24},
  copyright = {\textcopyright{} 2011 The Author},
  issn = {1741-4857},
  shorttitle = {Citing Data Sources in the Social Sciences},
  abstract = {It is expected that authors will provide citations for all papers referenced in their writings. The necessity of providing citations for data is not so widely recognized. Proponents of the data-sharing movement have advocated the citation of datasets in order to recognize contributions and enhance access. This study examines a sample of papers from the Inter-University Consortium for Political and Social Research (ICPSR) Bibliography of Data-Related Literature that are based on secondary analysis of datasets available in the ICPSR data archive to determine the data citation practices of authors. The results indicate that many authors fail to cite the data used in secondary analysis studies. Possible reasons for the dismal state of data citation practices are considered, including the recent introduction of data into the scholarly record and its marginalization as an information format. Updating citation practices to include datasets will support data sharing and foster responsible scholarship.},
  language = {en},
  number = {2},
  urldate = {2019-08-19},
  journal = {Learned Publishing},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1087/20110204},
  author = {Mooney, Hailey},
  year = {2011},
  pages = {99-108},
  file = {/home/stephan/Zotero/storage/3Y4IHS34/Mooney - 2011 - Citing data sources in the social sciences do aut.pdf;/home/stephan/Zotero/storage/E8YNH5NW/20110204.html}
}

@article{davisDatasetsShiftCurrency2007,
  title = {Datasets, a {{Shift}} in the {{Currency}} of {{Scholarly Communication}}: {{Implications}} for {{Library Collections}} and {{Acquisitions}}},
  volume = {33},
  issn = {0098-7913},
  shorttitle = {Datasets, a {{Shift}} in the {{Currency}} of {{Scholarly Communication}}},
  abstract = {As the market of scholarly communication continues to evolve, a number of indicators suggest that the unit of information currency is shifting from a primary focus on journal articles to a broader emphasis on key elements of scholarly communication, namely data sets. This article examines and summarizes recent developments that have contributed to this shift in emphasis. The authors will also consider how this shift may affect some of the core functions of the collections and acquisitions processes.},
  number = {1},
  urldate = {2019-08-19},
  journal = {Serials Review},
  url = {http://www.sciencedirect.com/science/article/pii/S0098791306001675},
  author = {Davis, Hilary M. and Vickery, John N.},
  month = mar,
  year = {2007},
  pages = {26-32},
  file = {/home/stephan/Zotero/storage/AKCDHB26/S0098791306001675.html}
}

@article{davisDatasetsShiftCurrency2007a,
  title = {Datasets, a {{Shift}} in the {{Currency}} of {{Scholarly Communication}}: {{Implications}} for {{Library Collections}} and {{Acquisitions}}},
  volume = {33},
  issn = {0098-7913},
  shorttitle = {Datasets, a {{Shift}} in the {{Currency}} of {{Scholarly Communication}}},
  abstract = {As the market of scholarly communication continues to evolve, a number of indicators suggest that the unit of information currency is shifting from a primary focus on journal articles to a broader emphasis on key elements of scholarly communication, namely data sets. This article examines and summarizes recent developments that have contributed to this shift in emphasis. The authors will also consider how this shift may affect some of the core functions of the collections and acquisitions processes.},
  number = {1},
  urldate = {2019-08-19},
  journal = {Serials Review},
  url = {https://www.tandfonline.com/doi/abs/10.1080/00987913.2007.10765089},
  author = {Davis, Hilary M. and Vickery, John N.},
  month = mar,
  year = {2007},
  pages = {26-32},
  file = {/home/stephan/Zotero/storage/44AY4WKN/00987913.2007.html}
}

@article{kratzMakingDataCount2015,
  title = {Making Data Count},
  volume = {2},
  copyright = {2015 Nature Publishing Group},
  issn = {2052-4463},
  abstract = {Making data count},
  language = {en},
  urldate = {2019-08-19},
  journal = {Scientific Data},
  url = {https://www.nature.com/articles/sdata201539},
  author = {Kratz, John E. and Strasser, Carly},
  month = aug,
  year = {2015},
  pages = {150039},
  file = {/home/stephan/Zotero/storage/U5PQ3VJV/Kratz and Strasser - 2015 - Making data count.pdf;/home/stephan/Zotero/storage/NE8CS263/sdata201539.html}
}

@article{vandesompelRethinkingScholarlyCommunication2004,
  title = {Rethinking {{Scholarly Communication}}: {{Building}} the {{System}} That {{Scholars Deserve}}},
  volume = {10},
  issn = {1082-9873},
  shorttitle = {Rethinking {{Scholarly Communication}}},
  language = {en},
  number = {9},
  urldate = {2019-08-19},
  journal = {D-Lib Magazine},
  url = {http://www.dlib.org/dlib/september04/vandesompel/09vandesompel.html},
  author = {{Van de Sompel}, Herbert and Payette, Sandy and Erickson, John and Lagoze, Carl and Warner, Simeon},
  month = sep,
  year = {2004}
}

@article{panHowImportantSoftware2019a,
  title = {How Important Is Software to Library and Information Science Research? {{A}} Content Analysis of Full-Text Publications},
  volume = {13},
  issn = {1751-1577},
  shorttitle = {How Important Is Software to Library and Information Science Research?},
  abstract = {We investigate the contributions of scientific software to library and information science (LIS) research using a sample of 572 English language articles published in 13 journals in 2008, 2011, 2014, and 2017. In particular, we examine the use and citation of software freely available for academic use in the LIS literature; we also explore the extent to which researchers follow software citation instructions provided by software developers. Twenty-seven percent of the LIS journal articles in our sample explicitly mention and use software. Yet although LIS researchers are becoming increasingly reliant on software that is freely available for academic use, many still fail to include formal citations of such software in their publications. We also find that a substantial proportion of researchers, when documenting software use, do not cite the software in the manner recommended by its developers.},
  number = {1},
  urldate = {2019-08-20},
  journal = {Journal of Informetrics},
  url = {http://www.sciencedirect.com/science/article/pii/S1751157718304504},
  author = {Pan, Xuelian and Yan, Erjia and Cui, Ming and Hua, Weina},
  month = feb,
  year = {2019},
  keywords = {Software,Bibliometrics,Citation analysis,Software citation,Scholarly communication},
  pages = {397-406},
  file = {/home/stephan/Zotero/storage/SRBQYTBI/Pan et al. - 2019 - How important is software to library and informati.pdf;/home/stephan/Zotero/storage/BYG3FN74/S1751157718304504.html}
}

@article{poisotBestPublishingPractices2015,
  title = {Best Publishing Practices to Improve User Confidence in Scientific Software},
  volume = {8},
  copyright = {Copyright (c) 2015 Timoth{\'e}e Poisot},
  issn = {1918-3178},
  language = {en},
  number = {1},
  urldate = {2019-08-20},
  journal = {Ideas in Ecology and Evolution},
  url = {https://ojs.library.queensu.ca/index.php/IEE/article/view/5644},
  author = {Poisot, Timoth{\'e}e},
  month = jul,
  year = {2015},
  keywords = {code,peer review,quality control},
  file = {/home/stephan/Zotero/storage/NP8VHL32/Poisot - 2015 - Best publishing practices to improve user confiden.pdf;/home/stephan/Zotero/storage/3W2TZ4I4/5644.html}
}

@article{garfieldCitationIndexesScience1955,
  title = {Citation {{Indexes}} for {{Science}}: {{A New Dimension}} in {{Documentation}} through {{Association}} of {{Ideas}}},
  volume = {122},
  copyright = {Copyright \textcopyright{} 1955 by the American Association for the Advancement of Science},
  issn = {0036-8075, 1095-9203},
  shorttitle = {Citation {{Indexes}} for {{Science}}},
  language = {en},
  number = {3159},
  urldate = {2019-08-20},
  journal = {Science},
  url = {https://science.sciencemag.org/content/122/3159/108},
  author = {Garfield, Eugene},
  month = jul,
  year = {1955},
  pages = {108-111},
  file = {/home/stephan/Zotero/storage/TQ6TCYTC/Garfield - 1955 - Citation Indexes for Science A New Dimension in D.pdf;/home/stephan/Zotero/storage/K6S5VUU6/108.html},
  pmid = {14385826}
}

@article{greenbergHowCitationDistortions2009,
  title = {How Citation Distortions Create Unfounded Authority: Analysis of a Citation Network},
  volume = {339},
  copyright = {\textcopyright{} Greenberg 2009. This is an open-access article distributed under the terms of the Creative Commons Attribution Non-commercial License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original work is properly cited.},
  issn = {0959-8138, 1468-5833},
  shorttitle = {How Citation Distortions Create Unfounded Authority},
  abstract = {Objective To understand belief in a specific scientific claim by studying the pattern of citations among papers stating it.
Design A complete citation network was constructed from all PubMed indexed English literature papers addressing the belief that {$\beta$} amyloid, a protein accumulated in the brain in Alzheimer's disease, is produced by and injures skeletal muscle of patients with inclusion body myositis. Social network theory and graph theory were used to analyse this network.
Main outcome measures Citation bias, amplification, and invention, and their effects on determining authority.
Results The network contained 242 papers and 675 citations addressing the belief, with 220 553 citation paths supporting it. Unfounded authority was established by citation bias against papers that refuted or weakened the belief; amplification, the marked expansion of the belief system by papers presenting no data addressing it; and forms of invention such as the conversion of hypothesis into fact through citation alone. Extension of this network into text within grants funded by the National Institutes of Health and obtained through the Freedom of Information Act showed the same phenomena present and sometimes used to justify requests for funding.
Conclusion Citation is both an impartial scholarly method and a powerful form of social communication. Through distortions in its social use that include bias, amplification, and invention, citation can be used to generate information cascades resulting in unfounded authority of claims. Construction and analysis of a claim specific citation network may clarify the nature of a published belief system and expose distorted methods of social citation.},
  language = {en},
  urldate = {2019-08-20},
  journal = {BMJ},
  url = {https://www.bmj.com/content/339/bmj.b2680},
  author = {Greenberg, Steven A.},
  month = jul,
  year = {2009},
  pages = {b2680},
  file = {/home/stephan/Zotero/storage/6MNRTMT9/Greenberg - 2009 - How citation distortions create unfounded authorit.pdf;/home/stephan/Zotero/storage/I65SB9GZ/bmj.html},
  pmid = {19622839}
}

@article{nicholasTrustAuthorityScholarly2014,
  title = {Trust and {{Authority}} in {{Scholarly Communications}} in the {{Light}} of the {{Digital Transition}}: Setting the Scene for a Major Study},
  volume = {27},
  copyright = {\textcopyright{} 2014 The Authors},
  issn = {1741-4857},
  shorttitle = {Trust and {{Authority}} in {{Scholarly Communications}} in the {{Light}} of the {{Digital Transition}}},
  abstract = {The paper provides the results of the first phase of the research project Trust and Authority in Scholarly Communications in the Light of the Digital Transition. It provides for an examination of the behaviours and attitudes of academic researchers as producers and consumers of scholarly information resources in the digital era in respect to how they determine authority and trustworthiness in the sources they use, cite, and publish in. The first phase of the study utilized focus groups to formulate research questions for the project as a whole. It provided the direction for the literature review, interviews, and questionnaires studies that would follow. Fourteen focus groups were held in the UK and US in order to obtain this information. A total of 66 science and social science researchers participated. The main findings were: (a) researchers play down difficulties of establishing trustworthiness, not because there are none, but because they have well-developed methods of establishing trust; (b) citation-derived metrics are becoming more important in regard to where researchers publish; (c) social media are ancillary to research, but are used for promotion of research and idea generation; (d) researchers are suspicious and confused about open access, but less so if produced by a traditional publisher; (e) there was a uniformity of perceptions/behaviour of researchers irrespective of differences in subject, country, and age; (f) although some early career researchers behave the same as their more senior colleagues this is because of a fear of the system: they actually think differently.},
  language = {en},
  number = {2},
  urldate = {2019-08-20},
  journal = {Learned Publishing},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1087/20140206},
  author = {Nicholas, David and Watkinson, Anthony and Volentine, Rachel and Allard, Suzie and Levine, Kenneth and Tenopir, Carol and Herman, Eti},
  year = {2014},
  pages = {121-134},
  file = {/home/stephan/Zotero/storage/HIFJHSD5/Nicholas et al. - 2014 - Trust and Authority in Scholarly Communications in.pdf;/home/stephan/Zotero/storage/SBW7KHPL/20140206.html}
}

@incollection{bungeEpistemicChange1983,
  address = {{Dordrecht}},
  series = {Treatise on {{Basic Philosophy}}},
  title = {Epistemic {{Change}}},
  isbn = {978-94-015-6921-7},
  abstract = {Knowledge, like food, can be stored\textemdash{}for a while. Some of it becomes stale and is eventually recognized as useless, or is no longer of interest to anyone. And whatever does stay is bound to become incorporated into more comprehensive and deeper bodies of knowledge. (Even the immortal Pythagorean theorem has become a particular case of a more general theorem in Riemannian geometry.) Therefore the investigator must be always on the run if he wishes to stay in the same place.},
  language = {en},
  urldate = {2019-08-20},
  booktitle = {Epistemology \& {{Methodology II}}: {{Understanding}} the {{World}}},
  publisher = {{Springer Netherlands}},
  url = {https://doi.org/10.1007/978-94-015-6921-7_4},
  author = {Bunge, M.},
  editor = {Bunge, M.},
  year = {1983},
  keywords = {Conceptual Framework,Modern Civilization,Rival Theory,Social Innovation,Thought Style},
  pages = {157-193},
  doi = {10.1007/978-94-015-6921-7_4}
}

@misc{daniels.katzCitationReproducibilitySoftware00:56:18UTC,
  type = {Software},
  title = {Citation and Reproducibility in Software},
  copyright = {Lizenz: CC Attribution License},
  abstract = {A talk about citation and reproducibility in software, presented at the HSF (},
  urldate = {2019-08-20},
  url = {https://de.slideshare.net/danielskatz/citation-and-reproducibility-in-software},
  author = {Daniel S. Katz},
  year = {00:56:18 UTC},
  file = {/home/stephan/Zotero/storage/3XNHEKTX/Daniel S. Katz - Citation and reproducibility in software.pdf}
}

@article{berez-kroekerReproducibleResearchLinguistics2018,
  title = {Reproducible Research in Linguistics: {{A}} Position Statement on Data Citation and Attribution in Our Field},
  volume = {56},
  issn = {0024-3949},
  shorttitle = {Reproducible Research in Linguistics},
  abstract = {This paper is a position statement on reproducible research in linguistics, including data citation and attribution, that represents the collective views of some 41 colleagues. Reproducibility can play a key role in increasing verification and accountability in linguistic research, and is a hallmark of social science research that is currently under-represented in our field. We believe that we need to take time as a discipline to clearly articulate our expectations for how linguistic data are managed, cited, and maintained for long-term access.},
  number = {1},
  urldate = {2019-08-20},
  journal = {Linguistics},
  url = {https://www.degruyter.com/view/j/ling.2018.56.issue-1/ling-2017-0032/ling-2017-0032.xml},
  author = {{Berez-Kroeker}, Andrea L. and Gawne, Lauren and Kung, Susan Smythe and Kelly, Barbara F. and Heston, Tyler and Holton, Gary and Pulsifer, Peter and Beaver, David I. and Chelliah, Shobhana and Dubinsky, Stanley and Meier, Richard P. and Thieberger, Nick and Rice, Keren and Woodbury, Anthony C.},
  year = {2018},
  keywords = {attribution,data citation,reproducibility},
  pages = {1--18},
  file = {/home/stephan/Zotero/storage/JLIASLE5/Berez-Kroeker et al. - 2018 - Reproducible research in linguistics A position s.pdf}
}

@misc{mangrooReproducibilityScienceHow,
  title = {Reproducibility in {{Science}}: {{How Proper Antibody Citation Can Make}} a {{Difference}}},
  shorttitle = {Reproducibility in {{Science}}},
  abstract = {Designing experiments is not an easy process. I can relate, having recently been at the bench myself before joining the BenchSci team.},
  language = {en-us},
  urldate = {2019-08-20},
  url = {http://web.archive.org/web/20190820124345/https://blog.benchsci.com/reproducibility-in-science-how-proper-antibody-citation-can-make-a-difference},
  author = {Mangroo, Casandra},
  file = {/home/stephan/Zotero/storage/8CZQI25G/reproducibility-in-science-how-proper-antibody-citation-can-make-a-difference.html}
}

@article{cousijnDataCitationRoadmap2018,
  title = {A Data Citation Roadmap for Scientific Publishers},
  volume = {5},
  copyright = {2018 Nature Publishing Group},
  issn = {2052-4463},
  abstract = {This article presents a practical roadmap for scholarly publishers to implement data citation in accordance with the Joint Declaration of Data Citation Principles (JDDCP), a synopsis and harmonization of the recommendations of major science policy bodies. It was developed by the Publishers Early Adopters Expert Group as part of the Data Citation Implementation Pilot (DCIP) project, an initiative of FORCE11.org and the NIH BioCADDIE program. The structure of the roadmap presented here follows the ``life of a paper'' workflow and includes the categories Pre-submission, Submission, Production, and Publication. The roadmap is intended to be publisher-agnostic so that all publishers can use this as a starting point when implementing JDDCP-compliant data citation. Authors reading this roadmap will also better know what to expect from publishers and how to enable their own data citations to gain maximum impact, as well as complying with what will become increasingly common funder mandates on data transparency.},
  language = {en},
  urldate = {2019-08-20},
  journal = {Scientific Data},
  url = {https://www.nature.com/articles/sdata2018259},
  author = {Cousijn, Helena and Kenall, Amye and Ganley, Emma and Harrison, Melissa and Kernohan, David and Lemberger, Thomas and Murphy, Fiona and Polischuk, Patrick and Taylor, Simone and Martone, Maryann and Clark, Tim},
  month = nov,
  year = {2018},
  pages = {180259},
  file = {/home/stephan/Zotero/storage/2EF3VFMU/Cousijn et al. - 2018 - A data citation roadmap for scientific publishers.pdf;/home/stephan/Zotero/storage/7IMS2JLX/sdata2018259.html}
}

@article{brancoReplicabilityReproducibilityResearch2017,
  title = {Replicability and Reproducibility of Research Results for Human Language Technology: Introducing an {{LRE}} Special Section},
  volume = {51},
  issn = {1574-020X, 1574-0218},
  shorttitle = {Replicability and Reproducibility of Research Results for Human Language Technology},
  language = {en},
  number = {1},
  urldate = {2019-08-20},
  journal = {Language Resources and Evaluation},
  url = {http://link.springer.com/10.1007/s10579-017-9380-0},
  author = {Branco, Ant{\'o}nio and Cohen, Kevin Bretonnel and Vossen, Piek and Ide, Nancy and Calzolari, Nicoletta},
  month = mar,
  year = {2017},
  pages = {1-5},
  file = {/home/stephan/Zotero/storage/FZKJ2WPX/Branco et al. - 2017 - Replicability and reproducibility of research resu.pdf}
}

@article{whiteCitationAnalysisDiscourse2004,
  title = {Citation {{Analysis}} and {{Discourse Analysis Revisited}}},
  volume = {25},
  issn = {0142-6001},
  abstract = {Abstract.  John Swales's 1986 article `Citation analysis and discourse analysis' was written by a discourse analyst to introduce citation research from other fi},
  language = {en},
  number = {1},
  urldate = {2019-08-20},
  journal = {Applied Linguistics},
  url = {https://academic.oup.com/applij/article/25/1/89/149106},
  author = {White, Howard D.},
  month = mar,
  year = {2004},
  pages = {89-116},
  file = {/home/stephan/Zotero/storage/LDCAZG3C/White - 2004 - Citation Analysis and Discourse Analysis Revisited.pdf}
}

@article{doerrGivingSoftwareIts2019,
  title = {Giving Software Its Due},
  volume = {16},
  copyright = {2019 Springer Nature America, Inc.},
  issn = {1548-7105},
  abstract = {Software and algorithm development is crucial for scientific progress; we discuss how to improve the impact and recognition of these tools.},
  language = {en},
  number = {3},
  urldate = {2019-08-23},
  journal = {Nature Methods},
  url = {https://doi.org/10.1038/s41592-019-0350-x},
  editor = {Doerr, Allison and Rusk, Nicole and Vogt, Nina and Strack, Rita and Tang, Lei and Arunima, Singh and Marx, Vivien},
  month = mar,
  year = {2019},
  pages = {207-207},
  file = {/home/stephan/Zotero/storage/VHFGABWE/2019 - Giving software its due.pdf;/home/stephan/Zotero/storage/8W7GPBIF/s41592-019-0350-x.html}
}

@inproceedings{howisonIncentivesIntegrationScientific2013,
  address = {{New York, NY, USA}},
  series = {{{CSCW}} '13},
  title = {Incentives and {{Integration}} in {{Scientific Software Production}}},
  isbn = {978-1-4503-1331-5},
  abstract = {Science policy makers are looking for approaches to increase the extent of collaboration in the production of scientific software, looking to open collaborations in open source software for inspiration. We examine the software ecosystem surrounding BLAST, a key bioinformatics tool, identifying outside improvements and interviewing their authors. We find that academic credit is a powerful motivator for the production and revealing of improvements. Yet surprisingly, we also find that improvements motivated by academic credit are less likely to be integrated than those with other motivations, including financial gain. We argue that this is because integration makes it harder to see who has contributed what and thereby undermines the ability of reputation to function as a reward for collaboration. We consider how open source avoids these issues and conclude with policy approaches to promoting wider collaboration by addressing incentives for integration.},
  urldate = {2019-08-23},
  booktitle = {Proceedings of the 2013 {{Conference}} on {{Computer Supported Cooperative Work}}},
  publisher = {{ACM}},
  url = {http://doi.acm.org/10.1145/2441776.2441828},
  author = {Howison, James and Herbsleb, James D.},
  year = {2013},
  keywords = {software development,collaboration,incentive systems,science policy},
  pages = {459--470},
  file = {/home/stephan/Zotero/storage/37GC9VUU/Howison and Herbsleb - 2013 - Incentives and Integration in Scientific Software .pdf}
}

@article{panAssessingImpactSoftware2015,
  title = {Assessing the Impact of Software on Science: {{A}} Bootstrapped Learning of Software Entities in Full-Text Papers},
  volume = {9},
  issn = {17511577},
  shorttitle = {Assessing the Impact of Software on Science},
  language = {en},
  number = {4},
  urldate = {2019-08-23},
  journal = {Journal of Informetrics},
  url = {https://linkinghub.elsevier.com/retrieve/pii/S1751157715300602},
  author = {Pan, Xuelian and Yan, Erjia and Wang, Qianqian and Hua, Weina},
  month = oct,
  year = {2015},
  pages = {860-871}
}

@article{liSoftwareCitationReuse2016,
  title = {Software Citation, Reuse and Metadata Considerations: {{An}} Exploratory Study Examining {{LAMMPS}}: {{Software Citation}}, {{Reuse}} and {{Metadata Considerations}}: {{An Exploratory Study Examining LAMMPS}}},
  volume = {53},
  issn = {23739231},
  shorttitle = {Software Citation, Reuse and Metadata Considerations},
  language = {en},
  number = {1},
  urldate = {2019-08-23},
  journal = {Proceedings of the Association for Information Science and Technology},
  url = {http://doi.wiley.com/10.1002/pra2.2016.14505301072},
  author = {Li, Kai and Lin, Xia and Greenberg, Jane},
  year = {2016},
  pages = {1-10},
  file = {/home/stephan/Zotero/storage/9QCJFDMK/Li et al. - 2016 - Software citation, reuse and metadata consideratio.pdf}
}

@article{gomez-diazEvaluationResearchSoftware2019,
  title = {On the Evaluation of Research Software: The {{CDUR}} Procedure},
  volume = {8},
  issn = {2046-1402},
  shorttitle = {On the Evaluation of Research Software},
  abstract = {Background:
              Evaluation of the quality of research software is a challenging and relevant issue, still not sufficiently addressed by the scientific community.
            
            
              Methods:
              Our contribution begins by defining, precisely but widely enough, the notions of research software and of its authors followed by a study of the evaluation issues, as the basis for the proposition of a sound assessment protocol: the CDUR procedure.
            
            
              Results:
              CDUR comprises four steps introduced as follows:
              C
              itation, to deal with correct RS identification,
              D
              issemination, to measure good dissemination practices,
              U
              se, devoted to the evaluation of usability aspects, and
              R
              esearch, to assess the impact of the scientific work.
            
            
              Conclusions:
              Some conclusions and recommendations are finally included. The evaluation of research is the keystone to boost the evolution of the Open Science policies and practices. ~It is as well our belief that research software evaluation is a fundamental step to induce better research software practices and, thus, a step towards more efficient science.},
  language = {en},
  urldate = {2019-08-23},
  journal = {F1000Research},
  url = {https://f1000research.com/articles/8-1353/v1},
  author = {{Gomez-Diaz}, Teresa and Recio, Tomas},
  month = aug,
  year = {2019},
  pages = {1353},
  file = {/home/stephan/Zotero/storage/T94WZLN2/Gomez-Diaz and Recio - 2019 - On the evaluation of research software the CDUR p.pdf;/home/stephan/Zotero/storage/3ZBTW2NU/v1.html}
}

@misc{boettigerCitingPackages2012,
  title = {Citing {{R}} Packages},
  urldate = {2019-08-23},
  url = {http://web.archive.org/web/20190823120400/https://www.carlboettiger.info/2012/03/20/citing-r-packages.html},
  author = {Boettiger, Carl},
  month = mar,
  year = {2012},
  file = {/home/stephan/Zotero/storage/PRKDQLGZ/citing-r-packages.html}
}

@inproceedings{bonischSwMATHNewInformation2013,
  series = {Lecture {{Notes}} in {{Computer Science}}},
  title = {{{swMATH}} \textendash{} {{A New Information Service}} for~{{Mathematical~Software}}},
  isbn = {978-3-642-39320-4},
  abstract = {An information service for mathematical software is presented. Publications and software are two closely connected facets of mathematical knowledge. This relation can be used to identify mathematical software and find relevant information about it. The approach and the state of the art of the information service are described here.},
  language = {en},
  booktitle = {Intelligent {{Computer Mathematics}}},
  publisher = {{Springer Berlin Heidelberg}},
  author = {B{\"o}nisch, Sebastian and Brickenstein, Michael and Chrapary, Hagen and Greuel, Gert-Martin and Sperber, Wolfram},
  editor = {Carette, Jacques and Aspinall, David and Lange, Christoph and Sojka, Petr and Windsteiger, Wolfgang},
  year = {2013},
  keywords = {Ematical Community,Information Service,Mathematical Software,Metadata Scheme,Software Reference},
  pages = {369-373}
}

@article{shamirPracticesSourceCode2013,
  title = {Practices in Source Code Sharing in Astrophysics},
  volume = {1},
  issn = {2213-1337},
  abstract = {While software and algorithms have become increasingly important in astronomy, the majority of authors who publish computational astronomy research do not share the source code they develop, making it difficult to replicate and reuse the work. In this paper we discuss the importance of sharing scientific source code with the entire astrophysics community, and propose that journals require authors to make their code publicly available when a paper is published. That is, we suggest that a paper that involves a computer program not be accepted for publication unless the source code becomes publicly available. The adoption of such a policy by editors, editorial boards, and reviewers will improve the ability to replicate scientific results, and will also make computational astronomy methods more available to other researchers who wish to apply them to their data.},
  urldate = {2019-08-23},
  journal = {Astronomy and Computing},
  url = {http://www.sciencedirect.com/science/article/pii/S2213133713000073},
  author = {Shamir, Lior and Wallin, John F. and Allen, Alice and Berriman, Bruce and Teuben, Peter and Nemiroff, Robert J. and Mink, Jessica and Hanisch, Robert J. and DuPrie, Kimberly},
  month = feb,
  year = {2013},
  keywords = {Source code,Software sharing,Open source,Scientific software,Software validation},
  pages = {54-58},
  file = {/home/stephan/Zotero/storage/5AMG283U/Shamir et al. - 2013 - Practices in source code sharing in astrophysics.pdf;/home/stephan/Zotero/storage/X5A2M5FN/S2213133713000073.html}
}

@misc{githubMakingYourCode2016,
  title = {Making {{Your Code Citable}} {$\cdot$} {{GitHub Guides}}},
  urldate = {2019-08-23},
  url = {http://web.archive.org/web/20190823123222/https://guides.github.com/activities/citable-code/},
  author = {GitHub},
  month = oct,
  year = {2016},
  file = {/home/stephan/Zotero/storage/YURJVV22/citable-code.html}
}

@book{kingscollegelondonTERESAHToolsEregistry2014,
  title = {{{TERESAH}}: {{Tools E}}-Registry for {{E}}-{{Social Sciences And Humanities}}},
  publisher = {{King's College London, Swedish National Data Service, Finnish Social Science Data Archive, University of Tartu, Universitat Pompeu Fabra and CentERdata}},
  url = {https://github.com/DASISH/TERESAH},
  author = {King's College London and Swedish National Data Service and Finnish Social Science Data Archive and {University of Tartu} and Universitat Pompeu Fabra and CentERdata},
  year = {2014}
}

@article{soitoCitationsSoftwareProviding2017,
  title = {Citations for {{Software}}: {{Providing Identification}}, {{Access}} and {{Recognition}} for {{Research Software}}},
  volume = {11},
  copyright = {Copyright (c)},
  issn = {1746-8256},
  shorttitle = {Citations for {{Software}}},
  language = {en},
  urldate = {2019-08-26},
  journal = {International Journal of Digital Curation},
  url = {http://www.ijdc.net/article/view/11.2.48},
  author = {Soito, Laura and Hwang, Lorraine J.},
  month = jul,
  year = {2017},
  keywords = {curation,DCC,digital curation,digital preservation,IJDC,International Journal of Digital Curation,preservation,definition-research-software},
  pages = {48-63},
  file = {/home/stephan/Zotero/storage/R7YDK3WQ/Soito and Hwang - 2017 - Citations for Software Providing Identification, .pdf;/home/stephan/Zotero/storage/T9ZHFE2U/11.2.html}
}

@misc{yaroslavhalchenkoDuecreditDuecredit2019,
  title = {Duecredit/Duecredit 0.7.0},
  abstract = {Automated collection and reporting of citations for used software/methods/datasets},
  urldate = {2019-08-26},
  howpublished = {Zenodo},
  url = {https://doi.org/10.5281/zenodo.3376261},
  author = {Yaroslav Halchenko and {Matteo Visconti di Oleggio Castello} and {jason gors} and Micha{\l} Szczepanik and Pradeep Reddy Raamana and {emirvine} and Chris Barnes and Chris Markiewicz and Jakub Wilk and Omer Faruk Gulban and Oliver Beckstein and Lo{\"i}c Est{\`e}ve and Katrin Leinweber and David V{\"o}lgyes},
  month = aug,
  year = {2019},
  file = {/home/stephan/Zotero/storage/F4UPVPVU/3376261.html},
  doi = {10.5281/zenodo.3376261}
}

@article{morinShiningLightBlack2012a,
  title = {Shining {{Light}} into {{Black Boxes}}},
  volume = {336},
  copyright = {Copyright \textcopyright{} 2012, American Association for the Advancement of Science},
  issn = {0036-8075, 1095-9203},
  abstract = {Funders, publishers, and research institutions must act to ensure that research computer code is made widely available.
Funders, publishers, and research institutions must act to ensure that research computer code is made widely available.},
  language = {en},
  number = {6078},
  urldate = {2019-08-26},
  journal = {Science},
  url = {https://science.sciencemag.org/content/336/6078/159},
  author = {Morin, A. and Urban, J. and Adams, P. D. and Foster, I. and Sali, A. and Baker, D. and Sliz, P.},
  month = apr,
  year = {2012},
  pages = {159-160},
  file = {/home/stephan/Zotero/storage/G4SJI95R/Morin et al. - 2012 - Shining Light into Black Boxes.pdf;/home/stephan/Zotero/storage/FU7ZH5GN/159.html},
  pmid = {22499926}
}

@article{pengReproducibleResearchComputational2011,
  title = {Reproducible {{Research}} in {{Computational Science}}},
  volume = {334},
  copyright = {Copyright \textcopyright{} 2011, American Association for the Advancement of Science},
  issn = {0036-8075, 1095-9203},
  abstract = {Computational science has led to exciting new developments, but the nature of the work has exposed limitations in our ability to evaluate published findings. Reproducibility has the potential to serve as a minimum standard for judging scientific claims when full independent replication of a study is not possible.},
  language = {en},
  number = {6060},
  urldate = {2019-08-26},
  journal = {Science},
  url = {https://science.sciencemag.org/content/334/6060/1226},
  author = {Peng, Roger D.},
  month = dec,
  year = {2011},
  pages = {1226-1227},
  file = {/home/stephan/Zotero/storage/C6YNWYPJ/Peng - 2011 - Reproducible Research in Computational Science.pdf;/home/stephan/Zotero/storage/QSQKUEJC/1226.html},
  pmid = {22144613}
}

@article{stoddenLegalFrameworkReproducible2009,
  title = {The {{Legal Framework}} for {{Reproducible Scientific Research}}: {{Licensing}} and {{Copyright}}},
  volume = {11},
  issn = {1521-9615},
  shorttitle = {The {{Legal Framework}} for {{Reproducible Scientific Research}}},
  abstract = {As computational researchers increasingly make their results available in a reproducible way, and often outside the traditional journal publishing mechanism, questions naturally arise with regard to copyright, subsequent use and citation, and ownership rights in general. The growing number of scientists who release their research publicly face a gap in the current licensing and copyright structure, particularly on the Internet. Scientific research produces more than the final paper: The code, data structures, experimental design and parameters, documentation, and figures are all important for scholarship communication and result replication. The author proposes the reproducible research standard for scientific researchers to use for all components of their scholarship that should encourage reproducible scientific investigation through attribution, facilitate greater collaboration, and promote engagement of the larger community in scientific learning and discovery.},
  number = {1},
  journal = {Computing in Science Engineering},
  doi = {10.1109/MCSE.2009.19},
  author = {Stodden, V.},
  month = jan,
  year = {2009},
  keywords = {licensing,Documentation,Licenses,electronic publishing,Internet,Collaboration,copyright,Data structures,Design for experiments,journal publishing mechanism,Law,Legal factors,legal framework,legislation,ownership rights,Publishing,reproducible research,reproducible scientific research,Scholarships,scientific discovery,scientific learning},
  pages = {35-40},
  file = {/home/stephan/Zotero/storage/IFEBAMKT/Stodden - 2009 - The Legal Framework for Reproducible Scientific Re.pdf;/home/stephan/Zotero/storage/I23A3MRJ/4720221.html}
}

@article{hansonMakingDataMaximally2011,
  title = {Making {{Data Maximally Available}}},
  volume = {331},
  copyright = {Copyright \textcopyright{} 2011, American Association for the Advancement of Science},
  issn = {0036-8075, 1095-9203},
  abstract = {Science is driven by data. New technologies have vastly increased the ease of data collection and consequently the amount of data collected, while also enabling data to be independently mined and reanalyzed by others. And society now relies on scientific data of diverse kinds; for example, in responding to disease outbreaks, managing resources, responding to climate change, and improving transportation. It is obvious that making data widely available is an essential element of scientific research. The scientific community strives to meet its basic responsibilities toward transparency, standardization, and data archiving. Yet, as pointed out in a special section of this issue (pp. [692\textendash{}729][1]), scientists are struggling with the huge amount, complexity, and variety of the data that are now being produced.

Recognizing the long shelf-life of data and their varied applications, and the close relation of data to the integrity of reported results, publishers, including Science , have increasingly assumed more responsibility for ensuring that data are archived and available after publication. Thus, Science and other journals have strengthened their policies regarding data, and as publishing moved online, added supporting online material (SOM) to expand data presentation and availability. But it is a growing challenge to ensure that data produced during the course of reported research are appropriately described, standardized, archived, and available to all.

![Figure][2]{$<$}/img{$>$}

CREDIT: THINKSTOCK

Science 's policy for some time has been that ``all data necessary to understand, assess, and extend the conclusions of the manuscript must be available to any reader of Science '' (see [www.sciencemag.org/site/feature/contribinfo/][3]). Besides prohibiting references to data in unpublished papers (including those described as ``in press''), we have encouraged authors to comply in one of two ways: either by depositing data in public databases that are reliably supported and likely to be maintained or, when such a database is not available, by including their data in the SOM. However, online supplements have too often become unwieldy, and journals are not equipped to curate huge data sets. For very large databases without a plausible home, we have therefore required authors to enter into an archiving agreement, in which the author commits to archive the data on an institutional Web site, with a copy of the data held at Science . But such agreements are only a stopgap solution; more support for permanent, community-maintained archives is badly needed.

To address the growing complexity of data and analyses, Science is extending our data access requirement listed above to include computer codes involved in the creation or analysis of data. To provide credit and reveal data sources more clearly, we will ask authors to produce a single list that combines references from the main paper and the SOM (this complete list will be available in the online version of the paper). And to improve the SOM, we will provide a template to constrain its content to methods and data descriptions, as an aid to reviewers and readers. We will also ask authors to provide a specific statement regarding the availability and curation of data as part of their acknowledgements, requesting that reviewers consider this a responsibility of the authors. We recognize that exceptions may be needed to these general requirements; for example, to preserve the privacy of individuals, or in some cases when data or materials are obtained from third parties, and/or for security reasons. But we expect these exceptions to be rare.

As gatekeepers to publication, journals clearly have an important part to play in making data publicly and permanently available. But the most important steps for improving the way that science is practiced and conveyed must come from the wider scientific community. Scientists play critical roles in the leadership of journals and societies, as reviewers for papers and grants, and as authors themselves. We must all accept that science is data and that data are science, and thus provide for, and justify the need for the support of, much-improved data curation.

 [1]: /lookup/volpage/331/692?iss=6018
 [2]: pending:yes
 [3]: http://www.sciencemag.org/site/feature/contribinfo/},
  language = {en},
  number = {6018},
  urldate = {2019-08-26},
  journal = {Science},
  url = {https://science.sciencemag.org/content/331/6018/649},
  author = {Hanson, Brooks and Sugden, Andrew and Alberts, Bruce},
  month = feb,
  year = {2011},
  keywords = {publishers-software-guidelines},
  pages = {649-649},
  file = {/home/stephan/Zotero/storage/G24X9K9I/Hanson et al. - 2011 - Making Data Maximally Available.pdf;/home/stephan/Zotero/storage/T2ZYCDV9/649.html},
  pmid = {21310971}
}

@unpublished{alliezAttributingReferencingResearch2019,
  title = {Attributing and {{Referencing}} ({{Research}}) {{Software}}: {{Best Practices}} and {{Outlook}} from {{Inria}}},
  shorttitle = {Attributing and {{Referencing}} ({{Research}}) {{Software}}},
  abstract = {Software is a fundamental pillar of modern scientific research, not only in computer science, but actually across all fields and disciplines. However, there is a lack of adequate means to cite and reference software, for many reasons. An obvious first reason is software authorship, which can range from a single developer to a whole team, and can even vary in time. The panorama is even more complex than that, because many roles can be involved in software development: software architect, coder, debugger, tester, team manager, and so on. Arguably, the researchers who have invented the key algorithms underlying the software can also claim a part of the authorship. And there are many other reasons that make this issue complex. We provide in this paper a contribution to the ongoing efforts to develop proper guidelines and recommendations for software citation, building upon the internal experience of Inria, the French research institute for digital sciences. As a central contribution, we make three key recommendations. (1) We propose a richer taxonomy for software contributions with a qualitative scale. (2) We claim that it is essential to put the human at the heart of the evaluation. And (3) we propose to distinguish citation from reference.},
  urldate = {2019-08-28},
  url = {https://hal.archives-ouvertes.fr/hal-02135891},
  author = {Alliez, Pierre and Di Cosmo, Roberto and Guedj, Benjamin and Girault, Alain and Hacid, Mohand-Said and Legrand, Arnaud and Rougier, Nicolas P.},
  month = may,
  year = {2019},
  keywords = {Software citation,Authorship,Development process,Reference},
  file = {/home/stephan/Zotero/storage/AY8IHWR7/Alliez et al. - 2019 - Attributing and Referencing (Research) Software B.pdf}
}

@article{theyalelawschoolroundtableondataandcoresharingReproducibleResearch2010,
  title = {Reproducible {{Research}}},
  volume = {12},
  issn = {1521-9615},
  abstract = {Roundtable participants identified ways of making computational research details readily available, which is a crucial step in addressing the current credibility crisis.},
  number = {5},
  journal = {Computing in Science Engineering},
  doi = {10.1109/MCSE.2010.113},
  author = {{The Yale Law School Round Table on Data {and} Core Sharing}},
  month = sep,
  year = {2010},
  keywords = {reproducible research,code sharing,Computational science,data sharing,scientific integrity,scientific method},
  pages = {8-13},
  file = {/home/stephan/Zotero/storage/ZIRPBPEB/2010 - Reproducible Research.pdf;/home/stephan/Zotero/storage/ZXEREV9F/5562471.html}
}

@article{marwickComputationalReproducibilityArchaeological2017,
  title = {Computational {{Reproducibility}} in {{Archaeological Research}}: {{Basic Principles}} and a {{Case Study}} of {{Their Implementation}}},
  volume = {24},
  issn = {1573-7764},
  shorttitle = {Computational {{Reproducibility}} in {{Archaeological Research}}},
  abstract = {The use of computers and complex software is pervasive in archaeology, yet their role in the analytical pipeline is rarely exposed for other researchers to inspect or reuse. This limits the progress of archaeology because researchers cannot easily reproduce each other's work to verify or extend it. Four general principles of reproducible research that have emerged in other fields are presented. An archaeological case study is described that shows how each principle can be implemented using freely available software. The costs and benefits of implementing reproducible research are assessed. The primary benefit, of sharing data in particular, is increased impact via an increased number of citations. The primary cost is the additional time required to enhance reproducibility, although the exact amount is difficult to quantify.},
  language = {en},
  number = {2},
  urldate = {2019-09-03},
  journal = {Journal of Archaeological Method and Theory},
  url = {https://doi.org/10.1007/s10816-015-9272-9},
  author = {Marwick, Ben},
  month = jun,
  year = {2017},
  keywords = {Software engineering,Australian archaeology,Computer programming,Open science,Reproducible research},
  pages = {424-450},
  file = {/home/stephan/Zotero/storage/25HDZYZJ/Marwick - 2017 - Computational Reproducibility in Archaeological Re.pdf}
}

@article{goodmanWhatDoesResearch2016,
  title = {What Does Research Reproducibility Mean?},
  volume = {8},
  copyright = {Copyright \textcopyright{} 2016, American Association for the Advancement of Science},
  issn = {1946-6234, 1946-6242},
  abstract = {The language and conceptual framework of ``research reproducibility'' are nonstandard and unsettled across the sciences. In this Perspective, we review an array of explicit and implicit definitions of reproducibility and related terminology, and discuss how to avoid potential misunderstandings when these terms are used as a surrogate for ``truth.''
The language and conceptual framework of ``research reproducibility'' are nonstandard and unsettled across the sciences.
The language and conceptual framework of ``research reproducibility'' are nonstandard and unsettled across the sciences.},
  language = {en},
  number = {341},
  urldate = {2019-09-03},
  journal = {Science Translational Medicine},
  url = {https://stm.sciencemag.org/content/8/341/341ps12},
  author = {Goodman, Steven N. and Fanelli, Daniele and Ioannidis, John P. A.},
  month = jun,
  year = {2016},
  pages = {341ps12-341ps12},
  file = {/home/stephan/Zotero/storage/RF6XJXHD/Goodman et al. - 2016 - What does research reproducibility mean.pdf;/home/stephan/Zotero/storage/U5ZDE43G/341ps12.html},
  pmid = {27252173}
}

@article{alnoamanyComputationalReproducibilityResearcher2018,
  title = {Towards Computational Reproducibility: Researcher Perspectives on the Use and Sharing of Software},
  volume = {4},
  issn = {2376-5992},
  shorttitle = {Towards Computational Reproducibility},
  abstract = {Research software, which includes both source code and executables used as part of the research process, presents a significant challenge for efforts aimed at ensuring reproducibility. In order to inform such efforts, we conducted a survey to better understand the characteristics of research software as well as how it is created, used, and shared by researchers. Based on the responses of 215 participants, representing a range of research disciplines, we found that researchers create, use, and share software in a wide variety of forms for a wide variety of purposes, including data collection, data analysis, data visualization, data cleaning and organization, and automation. More participants indicated that they use open source software than commercial software. While a relatively small number of programming languages (e.g., Python, R, JavaScript, C++, MATLAB) are used by a large number, there is a long tail of languages used by relatively few. Between-group comparisons revealed that significantly more participants from computer science write source code and create executables than participants from other disciplines. Differences between researchers from computer science and other disciplines related to the knowledge of best practices of software creation and sharing were not statistically significant. While many participants indicated that they draw a distinction between the sharing and preservation of software, related practices and perceptions were often not aligned with those of the broader scholarly communications community.},
  language = {en},
  urldate = {2019-09-03},
  journal = {PeerJ Computer Science},
  url = {https://peerj.com/articles/cs-163},
  author = {AlNoamany, Yasmin and Borghi, John A.},
  month = sep,
  year = {2018},
  pages = {e163},
  file = {/home/stephan/Zotero/storage/R2UYLQFL/AlNoamany and Borghi - 2018 - Towards computational reproducibility researcher .pdf;/home/stephan/Zotero/storage/9JK78C5T/cs-163.html}
}

@article{stoddenEnhancingReproducibilityComputational2016,
  title = {Enhancing Reproducibility for Computational Methods},
  volume = {354},
  copyright = {Copyright \textcopyright{} 2016, American Association for the Advancement of Science},
  issn = {0036-8075, 1095-9203},
  abstract = {Over the past two decades, computational methods have radically changed the ability of researchers from all areas of scholarship to process and analyze data and to simulate complex systems. But with these advances come challenges that are contributing to broader concerns over irreproducibility in the scholarly literature, among them the lack of transparency in disclosure of computational methods. Current reporting methods are often uneven, incomplete, and still evolving. We present a novel set of Reproducibility Enhancement Principles (REP) targeting disclosure challenges involving computation. These recommendations, which build upon more general proposals from the Transparency and Openness Promotion (TOP) guidelines (1) and recommendations for field data (2), emerged from workshop discussions among funding agencies, publishers and journal editors, industry participants, and researchers representing a broad range of domains. Although some of these actions may be aspirational, we believe it is important to recognize and move toward ameliorating irreproducibility in computational research.
Data, code, and workflows should be available and cited
Data, code, and workflows should be available and cited},
  language = {en},
  number = {6317},
  urldate = {2019-09-03},
  journal = {Science},
  url = {https://science.sciencemag.org/content/354/6317/1240},
  author = {Stodden, Victoria and McNutt, Marcia and Bailey, David H. and Deelman, Ewa and Gil, Yolanda and Hanson, Brooks and Heroux, Michael A. and Ioannidis, John P. A. and Taufer, Michela},
  month = dec,
  year = {2016},
  pages = {1240-1241},
  file = {/home/stephan/Zotero/storage/DZETQMEY/Stodden et al. - 2016 - Enhancing reproducibility for computational method.pdf;/home/stephan/Zotero/storage/TY6SVDIY/1240.html},
  pmid = {27940837}
}

@article{ivieReproducibilityScientificComputing2018,
  title = {Reproducibility in {{Scientific Computing}}},
  volume = {51},
  issn = {0360-0300},
  abstract = {Reproducibility is widely considered to be an essential requirement of the scientific process. However, a number of serious concerns have been raised recently, questioning whether today's computational work is adequately reproducible. In principle, it should be possible to specify a computation to sufficient detail that anyone should be able to reproduce it exactly. But in practice, there are fundamental, technical, and social barriers to doing so. The many objectives and meanings of reproducibility are discussed within the context of scientific computing. Technical barriers to reproducibility are described, extant approaches surveyed, and open areas of research are identified.},
  number = {3},
  urldate = {2019-09-03},
  journal = {ACM Comput. Surv.},
  url = {http://doi.acm.org/10.1145/3186266},
  author = {Ivie, Peter and Thain, Douglas},
  month = jul,
  year = {2018},
  keywords = {scientific workflows,Reproducibility,scientific computing,computational science,replicability,reproducible,scientific workflow,workflow,workflows},
  pages = {63:1--63:36},
  file = {/home/stephan/Zotero/storage/ZVBB7CRD/Ivie and Thain - 2018 - Reproducibility in Scientific Computing.pdf}
}

@article{crickReproducibilityResearchSystems2017,
  title = {Reproducibility in {{Research}}: {{Systems}}, {{Infrastructure}}, {{Culture}}},
  volume = {5},
  copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are \textcopyright, \textregistered{} or \texttrademark{} of their respective owners. No challenge to any owner's rights is intended or should be inferred.},
  issn = {2049-9647},
  shorttitle = {Reproducibility in {{Research}}},
  abstract = {The reproduction and replication of research results has become a major issue for a number of scientific disciplines. In computer science and related computational disciplines such as systems biology, the challenges closely revolve around the ability to implement (and exploit) novel algorithms and models. Taking a new approach from the literature and applying it to a new codebase frequently requires local knowledge missing from the published manuscripts and transient project websites. Alongside this issue, benchmarking, and the lack of open, transparent and fair benchmark sets present another barrier to the verification and validation of claimed results.

In this paper, we outline several recommendations to address these issues, driven by specific examples from a range of scientific domains. Based on these recommendations, we propose a high-level prototype open automated platform for scientific software development which effectively abstracts specific dependencies from the individual researcher and their workstation, allowing easy sharing and reproduction of results. This new e-infrastructure for reproducible computational science offers the potential to incentivise a culture change and drive the adoption of new techniques to improve the quality and efficiency \textendash{} and thus reproducibility \textendash{} of scientific exploration.},
  language = {en},
  number = {1},
  urldate = {2019-09-03},
  journal = {Journal of Open Research Software},
  url = {http://openresearchsoftware.metajnl.com/articles/10.5334/jors.73/},
  author = {Crick, Tom and Hall, Benjamin and Ishtiaq, Samin},
  month = nov,
  year = {2017},
  keywords = {scientific workflows,open science,reproducible research,computational science,code sharing,data sharing,best practices,cyberinfrastructure},
  pages = {32},
  file = {/home/stephan/Zotero/storage/U5Z2276R/Crick et al. - 2017 - Reproducibility in Research Systems, Infrastructu.pdf;/home/stephan/Zotero/storage/KGGVSACA/jors.html}
}

@article{fomelGuestEditorsIntroduction2009,
  title = {Guest {{Editors}}' {{Introduction}}: {{Reproducible Research}}},
  volume = {11},
  issn = {1521-9615},
  shorttitle = {Guest {{Editors}}' {{Introduction}}},
  abstract = {The articles in this special issue provide independent solutions for practical reproducible research systems. The use of Matlab-based tools such as the famous Wavelab and Sparselab packages in promoting reproducible research in computational harmonic analysis has been presented. In particular, the authors point to the success of the reproducible research discipline in increasing the reliability of computational research and reflect on the effort necessary for implementing this discipline in a research group and overcoming possible objections to it. An article also describes a Python interface to the well-known Clawpack package for solving hyperbolic partial differential equations that appear in wave propagation problems. The author argues strongly in favor of reproducible computations and shows an example using a simplified Python interface to Fortran code. An article also represents the field of bioinformatics, which has been a stronghold of reproducible research. It describes the cacher package, which is built on top of the R computing environment. Cacher enables a modular approach to reproducible computations by storing results of intermediate computations in a database. The special issue ends with an article on the legal aspects of reproducible research, including copyright and licensing issues.},
  number = {1},
  journal = {Computing in Science Engineering},
  doi = {10.1109/MCSE.2009.14},
  author = {Fomel, S. and Claerbout, J. F.},
  month = jan,
  year = {2009},
  keywords = {Standards development,copyright,reproducible research,Astronomy,bioinformatics,biology computing,cacher package,Clawpack package,computational harmonic analysis,computational research,computational science,FORTRAN,Fortran code,Geophysics computing,Humans,hyperbolic partial differential equations,Information analysis,intellectual property,licensing issues,mathematics computing,Matlab,Organizing,partial differential equations,Physics,Python interface,R computing,Roads,scientific publications,Sparselab,Standards publication,Testing,Wavelab},
  pages = {5-7},
  file = {/home/stephan/Zotero/storage/SPHEQYDS/Fomel and Claerbout - 2009 - Guest Editors' Introduction Reproducible Research.pdf;/home/stephan/Zotero/storage/JZZ9B427/4720217.html}
}

@misc{nielsenZenodoNowSupports2017,
  title = {Zenodo Now Supports {{DOI}} Versioning!},
  abstract = {European Open Science Infrastructure, for open scholarly and scientific communication},
  language = {en-gb},
  urldate = {2019-09-05},
  journal = {OpenAIRE},
  url = {http://web.archive.org/web/20190905092756/https://www.openaire.eu/blogs/zenodo-now-supports-doi-versioning-1},
  author = {Nielsen, Lars Holm},
  month = may,
  year = {2017},
  file = {/home/stephan/Zotero/storage/6CNK4KLN/zenodo-now-supports-doi-versioning-1.html}
}

@article{stoddenBestPracticesComputational2014,
  title = {Best {{Practices}} for {{Computational Science}}: {{Software Infrastructure}} and {{Environments}} for {{Reproducible}} and {{Extensible Research}}},
  volume = {2},
  copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are \textcopyright, \textregistered{} or \texttrademark{} of their respective owners. No challenge to any owner's rights is intended or should be inferred.},
  issn = {2049-9647},
  shorttitle = {Best {{Practices}} for {{Computational Science}}},
  abstract = {The goal of this article is to coalesce a discussion around best practices for scholarly research that utilizes computational methods, by providing a formalized set of best practice recommendations to guide computational scientists and other stakeholders wishing to disseminate reproducible research, facilitate innovation by enabling data and code re-use, and enable broader communication of the output of computational scientific research. Scholarly dissemination and communication standards are changing to reflect the increasingly computational nature of scholarly research, primarily to include the sharing of the data and code associated with published results. We also present these Best Practices as a living, evolving, and changing document at http://wiki.stodden.net/Best\_Practices.},
  language = {en},
  number = {1},
  urldate = {2019-09-04},
  journal = {Journal of Open Research Software},
  url = {http://openresearchsoftware.metajnl.com/articles/10.5334/jors.ay/},
  author = {Stodden, Victoria and Miguez, Sheila},
  month = jul,
  year = {2014},
  keywords = {open science,reproducible research,computational science,code sharing,data sharing,scientific method,best practices,archiving,wiki},
  pages = {e21},
  file = {/home/stephan/Zotero/storage/274ZF9QC/Stodden and Miguez - 2014 - Best Practices for Computational Science Software.pdf;/home/stephan/Zotero/storage/DLQEVJQV/jors.html}
}

@article{mcnuttTransparencyAuthorsContributions2018,
  title = {Transparency in Authors' Contributions and Responsibilities to Promote Integrity in Scientific Publication},
  volume = {115},
  abstract = {In keeping with the growing movement in scientific publishing toward transparency in data and methods, we propose changes to journal authorship policies and procedures to provide insight into which author is responsible for which contributions, better ...},
  language = {en},
  number = {11},
  urldate = {2019-09-06},
  journal = {Proceedings of the National Academy of Sciences of the United States of America},
  url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5856527/},
  author = {McNutt, Marcia K. and Bradford, Monica and Drazen, Jeffrey M. and Hanson, Brooks and Howard, Bob and Jamieson, Kathleen Hall and Kiermer, V{\'e}ronique and Marcus, Emilie and Pope, Barbara Kline and Schekman, Randy and Swaminathan, Sowmya and Stang, Peter J. and Verma, Inder M.},
  month = mar,
  year = {2018},
  pages = {2557},
  file = {/home/stephan/Zotero/storage/539ANRMA/McNutt et al. - 2018 - Transparency in authors’ contributions and respons.pdf;/home/stephan/Zotero/storage/S3P42KM4/PMC5856527.html},
  pmid = {29487213}
}

@inproceedings{constantinouDevelopersExpertiseRoles2016,
  title = {Developers {{Expertise}} and {{Roles}} on {{Software Technologies}}},
  abstract = {Contributions to open source software provide evidence about developers' expertise and roles. Moreover, information about developers' activity can assist in identifying their competencies in software technologies. Existing project-centric approaches benefit the needs of expert identification within a project, but provide a limited view of developers' expertise. In this paper, we identify contributors' expertise and roles by considering their contribution history across multiple projects according to different technologies. Firstly, we identify terms related to software technologies and employ information from GitHub to extract contributors' activity on specific technologies. Secondly, we present four contributor roles: developer, technical leader, bug fixer and bug contributor. We study the contribution history of 2,973 users of GitHub and reveal trends in contributions in open source software that can be exploited by employers for identifying experts or by practitioners for showcasing their expertise in various technologies.},
  booktitle = {2016 23rd {{Asia}}-{{Pacific Software Engineering Conference}} ({{APSEC}})},
  doi = {10.1109/APSEC.2016.061},
  author = {Constantinou, E. and Kapitsaki, G. M.},
  month = dec,
  year = {2016},
  keywords = {open source software,History,GitHub,bug contributor,bug fixer,Computer bugs,Computer languages,contributor activity extraction,Decision making,developer activity information,developer expertise,developer roles,Developers,Expertise,Maintenance engineering,Open source software,program debugging,project management,project-centric approaches,public domain software,software management,software technologies,technical leader,Technologies},
  pages = {365-368},
  file = {/home/stephan/Zotero/storage/95S2VBAB/Constantinou and Kapitsaki - 2016 - Developers Expertise and Roles on Software Technol.pdf;/home/stephan/Zotero/storage/SCDGZN9P/7890613.html}
}

@article{chengActivityBasedAnalysisOpen2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1903.05277},
  primaryClass = {cs},
  title = {Activity-{{Based Analysis}} of {{Open Source Software Contributors}}: {{Roles}} and {{Dynamics}}},
  shorttitle = {Activity-{{Based Analysis}} of {{Open Source Software Contributors}}},
  abstract = {Contributors to open source software (OSS) communities assume diverse roles to take different responsibilities. One major limitation of the current OSS tools and platforms is that they provide a uniform user interface regardless of the activities performed by the various types of contributors. This paper serves as a non-trivial first step towards resolving this challenge by demonstrating a methodology and establishing knowledge to understand how the contributors' roles and their dynamics, reflected in the activities contributors perform, are exhibited in OSS communities. Based on an analysis of user action data from 29 GitHub projects, we extracted six activities that distinguished four Active roles and five Supporting roles of OSS contributors, as well as patterns in role changes. Through the lens of the Activity Theory, these findings provided rich design guidelines for OSS tools to support diverse contributor roles.},
  urldate = {2019-09-06},
  journal = {arXiv:1903.05277 [cs]},
  url = {http://arxiv.org/abs/1903.05277},
  author = {Cheng, Jinghui and Guo, Jin L. C.},
  month = mar,
  year = {2019},
  keywords = {Computer Science - Software Engineering,Computer Science - Human-Computer Interaction},
  file = {/home/stephan/Zotero/storage/XMQJW23W/Cheng and Guo - 2019 - Activity-Based Analysis of Open Source Software Co.pdf;/home/stephan/Zotero/storage/36EMTIN8/1903.html}
}

@misc{RecognizeAllContributors,
  title = {Recognize All Contributors},
  abstract = {✨ Recognize all contributors, not just the ones who write code. ✨ All Contributors helps praise everyone contributing to open source projects.},
  language = {en},
  urldate = {2019-09-06},
  journal = {All Contributors},
  url = {http://web.archive.org/web/20190906132859/https://allcontributors.org/},
  file = {/home/stephan/Zotero/storage/W4VD4FY2/allcontributors.org.html}
}

@misc{HomeSchemaOrg,
  title = {Home - Schema.Org},
  urldate = {2019-09-06},
  url = {https://schema.org/},
  file = {/home/stephan/Zotero/storage/GZH938KF/schema.org.html}
}

@misc{ContributorSchemaOrg,
  title = {Contributor - Schema.Org},
  urldate = {2019-09-06},
  url = {http://web.archive.org/web/20190906141516/https://schema.org/contributor},
  file = {/home/stephan/Zotero/storage/2WPGG4PR/contributor.html}
}

@techreport{ahaltNSFWorkshopSupporting,
  title = {{{NSF Workshop}} on {{Supporting Scientific Discovery}} through {{Norms}} and {{Practices}} for {{Software}} and {{Data Citation}} and {{Attribution}}},
  language = {en},
  url = {http://web.archive.org/web/20190911211016/https://softwaredatacitation.renci.org/Workshop\%20Report/SoftwareDataCitation_workshop_report_2015_April_20_with_logo.pdf},
  author = {Ahalt, Stan and Carsey, Tom and Couch, Alva and Hooper, Rick and Ibanez, Luis and Idaszak, Ray and Jones, Matthew B. and Lin, Jennifer and Robinson, Erin},
  pages = {18},
  file = {/home/stephan/Zotero/storage/H7JHWGVQ/NSF Workshop on Supporting Scientific Discovery th.pdf}
}

@article{allenPublishingCreditWhere2014a,
  title = {Publishing: {{Credit}} Where Credit Is Due},
  volume = {508},
  shorttitle = {Publishing},
  abstract = {Liz Allen, Amy Brand, Jo Scott, Micah Altman and Marjorie Hlava are trialling digital taxonomies to help researchers to identify their contributions to collaborative projects.},
  language = {en},
  number = {7496},
  urldate = {2019-09-11},
  journal = {Nature News},
  url = {http://www.nature.com/news/publishing-credit-where-credit-is-due-1.15033},
  author = {Allen, Liz and Scott, Jo and Brand, Amy and Hlava, Marjorie and Altman, Micah},
  month = apr,
  year = {2014},
  pages = {312},
  file = {/home/stephan/Zotero/storage/HNTZAM2D/publishing-credit-where-credit-is-due-1.html}
}

@article{beckNISOZ39962011,
  title = {{{NISO Z39}}.96 {{The Journal Article Tag Suite}} ({{JATS}}): {{What Happened}} to the {{NLM DTDs}}?},
  volume = {14},
  issn = {1080-2711},
  shorttitle = {{{NISO Z39}}.96 {{The Journal Article Tag Suite}} ({{JATS}})},
  language = {en},
  number = {1},
  urldate = {2019-09-11},
  journal = {The Journal of Electronic Publishing},
  url = {http://hdl.handle.net/2027/spo.3336451.0014.106},
  author = {Beck, Jeffrey},
  month = aug,
  year = {2011},
  file = {/home/stephan/Zotero/storage/D2Q2MYWH/Beck - 2011 - NISO Z39.96 The Journal Article Tag Suite (JATS) .pdf}
}

@article{savicLanguageindependentApproachExtraction2014,
  title = {A Language-Independent Approach to the Extraction of Dependencies between Source Code Entities},
  volume = {56},
  issn = {0950-5849},
  abstract = {Context
Software networks are directed graphs of static dependencies between source code entities (functions, classes, modules, etc.). These structures can be used to investigate the complexity and evolution of large-scale software systems and to compute metrics associated with software design. The extraction of software networks is also the first step in reverse engineering activities.
Objective
The aim of this paper is to present SNEIPL, a novel approach to the extraction of software networks that is based on a language-independent, enriched concrete syntax tree representation of the source code.
Method
The applicability of the approach is demonstrated by the extraction of software networks representing real-world, medium to large software systems written in different languages which belong to different programming paradigms. To investigate the completeness and correctness of the approach, class collaboration networks (CCNs) extracted from real-world Java software systems are compared to CCNs obtained by other tools. Namely, we used Dependency Finder which extracts entity-level dependencies from Java bytecode, and Doxygen which realizes language-independent fuzzy parsing approach to dependency extraction. We also compared SNEIPL to fact extractors present in language-independent reverse engineering tools.
Results
Our approach to dependency extraction is validated on six real-world medium to large-scale software systems written in Java, Modula-2, and Delphi. The results of the comparative analysis involving ten Java software systems show that the networks formed by SNEIPL are highly similar to those formed by Dependency Finder and more precise than the comparable networks formed with the help of Doxygen. Regarding the comparison with language-independent reverse engineering tools, SNEIPL provides both language-independent extraction and representation of fact bases.
Conclusion
SNEIPL is a language-independent extractor of software networks and consequently enables language-independent network-based analysis of software systems, computation of design software metrics, and extraction of fact bases for reverse engineering activities.},
  number = {10},
  urldate = {2019-09-10},
  journal = {Information and Software Technology},
  url = {http://www.sciencedirect.com/science/article/pii/S0950584914000925},
  author = {Savi{\'c}, Milo{\v s} and Raki{\'c}, Gordana and Budimac, Zoran and Ivanovi{\'c}, Mirjana},
  month = oct,
  year = {2014},
  keywords = {Dependency extraction,Enriched concrete syntax tree,Fact extraction,Reverse engineering,Software metrics,Software networks},
  pages = {1268-1288},
  file = {/home/stephan/Zotero/storage/YCXVJKWJ/Savić et al. - 2014 - A language-independent approach to the extraction .pdf;/home/stephan/Zotero/storage/23TXHJZE/S0950584914000925.html}
}

@article{druskatSoftwareDependenciesResearch2019,
  title = {Software and {{Dependencies}} in {{Research Citation Graphs}}},
  copyright = {All rights reserved},
  issn = {1558-366X},
  abstract = {Following the widespread digitalization of scholarship, software has become essential for research, but the current sociotechnical system of citation does not reflect this sufficiently. Citation provides context for research, but the current model for the respective research citation graphs does not integrate software. In this paper, I develop a directed graph model to alleviate this, describe challenges for its instantiation, and give an outlook of useful applications of research citation graphs, including transitive credit.},
  journal = {Computing in Science and Engineering},
  url = {https://doi.org/10.1109/MCSE.2019.2952840},
  author = {Druskat, Stephan},
  year = {2019},
  keywords = {citation graphs,Computational modeling,Guidelines,Metadata,Scholarships,Sociotechnical systems,Software,software citation,Stakeholders,transitive credit},
  pages = {1-1},
  file = {/home/stephan/Zotero/storage/Z4AF3DCL/Druskat - 2019 - Software and Dependencies in Research Citation Gra.pdf;/home/stephan/Zotero/storage/EFGXSQPK/8896031.html}
}


